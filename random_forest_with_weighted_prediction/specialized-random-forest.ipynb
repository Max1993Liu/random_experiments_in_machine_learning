{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# use the creditcard default dataset\n",
    "df = pd.read_excel(r'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['ID', 'default payment next month'], axis=1)\n",
    "y = df['default payment next month']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline  \n",
    "- plain random forest with equal weight for each decision tree in the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       1.940685\n",
       "score_time     0.064801\n",
       "test_score     0.775301\n",
       "train_score    0.792621\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=1024)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=1024)\n",
    "baseline_result = cross_validate(rf, X, y, scoring='roc_auc', cv=cv, return_train_score=True)\n",
    "pd.DataFrame(baseline_result).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1  \n",
    "- The assumption is that each tree is better at predicting samples in a small subspace, so during inference time the output of each tree is weighted based on whether the instance falls into the subspace that it's good at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecializedForestClassifier(RandomForestClassifier):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_neighbours=200,\n",
    "                 metric='auc',\n",
    "                 weight_fn='square',\n",
    "                 n_estimators='warn',\n",
    "                 criterion=\"gini\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=\"auto\",\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=0.,\n",
    "                 min_impurity_split=None,\n",
    "                 bootstrap=True,\n",
    "                 oob_score=False,\n",
    "                 n_jobs=None,\n",
    "                 random_state=None,\n",
    "                 verbose=0,\n",
    "                 warm_start=False,\n",
    "                 class_weight=None):\n",
    "        super().__init__(\n",
    "                n_estimators=n_estimators,\n",
    "                 criterion=criterion,\n",
    "                 max_depth=max_depth,\n",
    "                 min_samples_split=min_samples_split,\n",
    "                 min_samples_leaf=min_samples_leaf,\n",
    "                 min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                 max_features=max_features,\n",
    "                 max_leaf_nodes=max_leaf_nodes,\n",
    "                 min_impurity_decrease=min_impurity_decrease,\n",
    "                 min_impurity_split=min_impurity_split,\n",
    "                 bootstrap=bootstrap,\n",
    "                 oob_score=oob_score,\n",
    "                 n_jobs=n_jobs,\n",
    "                 random_state=random_state,\n",
    "                 verbose=verbose,\n",
    "                 warm_start=warm_start,\n",
    "                 class_weight=class_weight\n",
    "            )\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.metric = metric\n",
    "        self.weight_fn = weight_fn\n",
    "        \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        super().fit(X, y, sample_weight)\n",
    "        # convert to array\n",
    "        self.X_train = X.values if hasattr(X, 'values') else X\n",
    "        self.y_train = y.values if hasattr(y, 'values') else y\n",
    "        self.nbrs = NearestNeighbors(n_neighbors=self.n_neighbours, metric='l2')\n",
    "        self.nbrs.fit(X, y)\n",
    "        return self\n",
    "            \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        if self.metric in ('auc', 'roc_auc'):\n",
    "            metric_fn = roc_auc_score\n",
    "        elif isinstance(self.metric, str):\n",
    "            raise\n",
    "        else:\n",
    "            metric_fn = self.metric\n",
    "        \n",
    "        if self.weight_fn == 'square':\n",
    "            weight_fn = np.square\n",
    "        elif self.weight_fn == 'sqrt':\n",
    "            weight_fn = np.sqrt\n",
    "        elif self.weight_fn in ('exp', 'exponential'):\n",
    "            weight_fn = np.exp\n",
    "        elif isinstance(self.weight_fn, str):\n",
    "            raise ValueError('{} is not supported.'.format(self.weight_fn))\n",
    "        else:\n",
    "            weight_fn = np.vectorize(self.weight_fn)\n",
    "\n",
    "        # get the prediction for each base classifier\n",
    "        # prediction.shape = [n_sample, n_classifier]\n",
    "        prediction = np.empty((len(X), len(self.estimators_)))\n",
    "        for i, est in enumerate(self.estimators_):\n",
    "            prediction[:, i] = est.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # calculate the benchmark indices for X, shape = [n_sample, n_neighbours]\n",
    "        dist, benchmark_indices = self.nbrs.kneighbors(X)\n",
    "        \n",
    "        metrics = np.empty((len(X), len(self.estimators_)))\n",
    "        for sample_idx in trange(len(X)):\n",
    "            X_benchmark = self.X_train[benchmark_indices[sample_idx]]\n",
    "            y_benchmark = self.y_train[benchmark_indices[sample_idx]]\n",
    "            for est_idx, est in enumerate(self.estimators_):\n",
    "                pred = est.predict_proba(X_benchmark)[:, 1]            \n",
    "                metrics[sample_idx, est_idx] = metric_fn(y_benchmark, pred)\n",
    "        \n",
    "        # the metric rank for each sample in ascending order\n",
    "        metric_rank = metrics.argsort()\n",
    "        metric_rank = metric_rank.astype('float') + 1e-10\n",
    "        \n",
    "        # the weight for each prediction based on the rank of the metrics\n",
    "        pred_weight = weight_fn(metric_rank)\n",
    "        pred_weight = pred_weight / pred_weight.sum(axis=1, keepdims=True)\n",
    "        prediction = prediction * pred_weight\n",
    "        prediction = prediction.mean(axis=1)\n",
    "        return np.array([1-prediction, prediction]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9000/9000 [13:44<00:00, 10.91it/s]\n",
      " 12%|█▏        | 2591/21000 [1:05:58<29:34, 10.37it/s]      "
     ]
    }
   ],
   "source": [
    "S = SpecializedForestClassifier(n_neighbours=500, n_estimators=100, max_depth=5)\n",
    "exp1_res = cross_validate(S, X, y, scoring='roc_auc', cv=cv, return_train_score=True)\n",
    "pd.DataFrame(exp1_res).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759849268920873"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='l2',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=100, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbours = 100\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=n_neighbours,\n",
    "                       metric='l2')\n",
    "\n",
    "nbrs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, branchmark_indices = nbrs.kneighbors(X_test[:10])\n",
    "\n",
    "# get the benchmark dataset to evaluate the performance for each base classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[600000,      2,      2, ...,   2186,   2310,   7511],\n",
       "       [620000,      2,      1, ...,   2856,   4197,    920],\n",
       "       [600000,      1,      1, ...,    601,      0,    492],\n",
       "       ...,\n",
       "       [500000,      1,      1, ...,   2010,      0,   4642],\n",
       "       [500000,      2,      2, ...,  10000,  10000,  25304],\n",
       "       [500000,      1,      1, ...,  24010,  15000,  20000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[ 2466 18299 20636 17493   999 11182 16268  4650 19504  4708   505  8602\\n 19616  8887 14879 19168  6621  6576  3612  7353  6131  6898  9427  8732\\n  2451  1704 10540  8110 12487 12826 13969  5399 17846  9108 17445  2255\\n 11788  4443  2694 11597 15066  2314  9979  1944 14902 20374 19665 20506\\n  7629  8135  3822 16404 18472 14703 10987 18607 13805 17578 14696 11606\\n  3795  2984 15418 11331  8094  2499 15891  4048 16068  7136 13706  2809\\n 10812 17730  2478 14898 18290 16686  2838 20630  2841  2632  4017  9727\\n  8874 19244 12847  1231  9838  3251  7656 15165  9562 17913 17495  7742\\n 16927  8221  1105  1605] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-12378a5ea26b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2722\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2723\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[ 2466 18299 20636 17493   999 11182 16268  4650 19504  4708   505  8602\\n 19616  8887 14879 19168  6621  6576  3612  7353  6131  6898  9427  8732\\n  2451  1704 10540  8110 12487 12826 13969  5399 17846  9108 17445  2255\\n 11788  4443  2694 11597 15066  2314  9979  1944 14902 20374 19665 20506\\n  7629  8135  3822 16404 18472 14703 10987 18607 13805 17578 14696 11606\\n  3795  2984 15418 11331  8094  2499 15891  4048 16068  7136 13706  2809\\n 10812 17730  2478 14898 18290 16686  2838 20630  2841  2632  4017  9727\\n  8874 19244 12847  1231  9838  3251  7656 15165  9562 17913 17495  7742\\n 16927  8221  1105  1605] not in index'"
     ]
    }
   ],
   "source": [
    "X_train[indices[0].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
