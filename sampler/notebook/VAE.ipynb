{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09720062208398134"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will be using satimage data as in the Borderline-SMOTE paper\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "data = fetch_openml(name='satimage')\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "# treat 4 as the target class\n",
    "y = (y=='4.').astype(int)\n",
    "y.mean()\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the baseline model does without any over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
    "                                                    stratify=y, shuffle=True, random_state=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf):\n",
    "    pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    pred = clf.predict(X_test)\n",
    "    metric = 'AUC: {}\\nRecall: {}\\nPrecision: {}\\nF1: {}\\n'.format(roc_auc_score(y_test, pred_proba),\n",
    "                                                              recall_score(y_test, pred),\n",
    "                                                              precision_score(y_test, pred),\n",
    "                                                              f1_score(y_test, pred))\n",
    "    print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9521398804795482\n",
      "Recall: 0.5106382978723404\n",
      "Precision: 0.8347826086956521\n",
      "F1: 0.6336633663366336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "evaluate(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9588919305363754\n",
      "Recall: 0.6329787234042553\n",
      "Precision: 0.6432432432432432\n",
      "F1: 0.6380697050938338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "clf.fit(*SMOTE().fit_resample(X_train, y_train))\n",
    "\n",
    "evaluate(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T19:17:29.886938Z",
     "start_time": "2019-05-10T19:17:26.656978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from tensorflow import keras\n",
    "\n",
    "# the nightly build of tensorflow_probability is required as of the time of writing this \n",
    "import tensorflow_probability as tfp\n",
    "ds = tfp.distributions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    mean_, var_ = tf.nn.moments(x, axes=[0], keepdims=True)\n",
    "    return (x - mean_) / tf.sqrt(var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURE = X_train.shape[1]\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train.values.astype('float32')) \\\n",
    "    .shuffle(10000).batch(BATCH_SIZE).map(standardize)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test.values.astype('float32')) \\\n",
    "    .shuffle(10000).batch(10000).map(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_encoder_decoder(hidden_size=4, share_hidden=False):\n",
    "    \"\"\" If share hidden is set to False, then the actual hidden_size will be 2 * hidden_size\n",
    "        and it will split in half into the mean and std vector\n",
    "    \"\"\"\n",
    "    if share_hidden is False:\n",
    "        hidden_size = hidden_size * 2\n",
    "        \n",
    "    encoder = tf.keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(N_FEATURE,)),\n",
    "        keras.layers.Dense(36, activation=None),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(18, activation=None),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(hidden_size)\n",
    "    ])\n",
    "\n",
    "    decoder = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(18, activation=None),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(36, activation=None),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(N_FEATURE)\n",
    "    ])\n",
    "    \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                666       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 152       \n",
      "=================================================================\n",
      "Total params: 2,150\n",
      "Trainable params: 2,150\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# take a look at the encoder and decoders\n",
    "e_, d_ = make_encoder_decoder()\n",
    "e_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gradients(gradients):\n",
    "    \"\"\" Handy function to check the gradients, in case we get nans from gradient explotion \"\"\"\n",
    "    grad = [i.numpy() for i in gradients]\n",
    "    if all([np.isfinite(g).all() for g in grad]):\n",
    "        avg_grad = [np.mean(g) for g in grad]\n",
    "        mean_, std_ = np.mean(avg_grad), np.std(avg_grad)\n",
    "        print('Gradients stats: mean={}, std={}'.format(mean_, std_))\n",
    "    else:\n",
    "        print('Gradient exploded: {}'.format(grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, optimizer, hidden_size=8, share_hidden=False):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.share_hidden = share_hidden\n",
    "        self.encoder, self.decoder = make_encoder_decoder(hidden_size, share_hidden)\n",
    "        \n",
    "        # only used when share hidden is True\n",
    "        self.dense_mean = keras.layers.Dense(hidden_size)\n",
    "        self.dense_std = keras.layers.Dense(hidden_size)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def encode(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        if self.share_hidden:\n",
    "            mu, sigma = self.dense_mean(encoded), self.dense_std(encoded)\n",
    "        else:\n",
    "            mu, sigma = tf.split(encoded, num_or_size_splits=2, axis=1)\n",
    "        return mu, sigma, ds.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        mu, sigma, q_z = self.encode(x)\n",
    "        z = sigma * q_z.sample() + mu\n",
    "#         z = q_z.sample()\n",
    "        x_recon = self.decode(z)\n",
    "        \n",
    "        # standard normal distribution\n",
    "        p_z = ds.MultivariateNormalDiag(loc=[0.] * z.shape[-1], scale_diag=[1.] * z.shape[-1])\n",
    "        kl_div = ds.kl_divergence(q_z, p_z)\n",
    "        latent_loss = tf.reduce_mean(tf.maximum(kl_div, 0))\n",
    "        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square(x - x_recon), axis=0))\n",
    "        return latent_loss, recon_loss\n",
    "    \n",
    "    def compute_gradients(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            latent_loss, recon_loss = self.compute_loss(x)\n",
    "            loss = (latent_loss + recon_loss) / 2\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        return gradients\n",
    "#         grad = [g.numpy() for g in gradients]\n",
    "#         if all([np.isfinite(g).all() for g in grad]):\n",
    "#             return gradients\n",
    "#         else:\n",
    "#             print('Gradient exploded.')\n",
    "#             return None\n",
    "        \n",
    "    @tf.function\n",
    "    def train(self, train_x):\n",
    "        gradients = self.compute_gradients(train_x)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05477e0b9ce41b78b0500055cd4f435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | recon_loss: 4.806938171386719 | latent_loss: 491.7444152832031 | total_loss: 248.2756805419922\n",
      "Epoch: 1 | recon_loss: 5.300199508666992 | latent_loss: 459.9679870605469 | total_loss: 232.63409423828125\n",
      "Epoch: 2 | recon_loss: 6.345351219177246 | latent_loss: 410.3187255859375 | total_loss: 208.33203125\n",
      "Epoch: 3 | recon_loss: 6.835157871246338 | latent_loss: 357.885498046875 | total_loss: 182.36032104492188\n",
      "Epoch: 4 | recon_loss: 7.614360332489014 | latent_loss: 305.77545166015625 | total_loss: 156.6949005126953\n",
      "Epoch: 5 | recon_loss: 8.2001371383667 | latent_loss: 258.0861511230469 | total_loss: 133.1431427001953\n",
      "Epoch: 6 | recon_loss: 8.86193561553955 | latent_loss: 198.5189971923828 | total_loss: 103.69046783447266\n",
      "Epoch: 7 | recon_loss: 9.089988708496094 | latent_loss: 166.1655731201172 | total_loss: 87.62777709960938\n",
      "Epoch: 8 | recon_loss: 9.112393379211426 | latent_loss: 138.74818420410156 | total_loss: 73.93029022216797\n",
      "Epoch: 9 | recon_loss: 9.492551803588867 | latent_loss: 121.61724090576172 | total_loss: 65.55489349365234\n",
      "Epoch: 10 | recon_loss: 9.825956344604492 | latent_loss: 108.94003295898438 | total_loss: 59.38299560546875\n",
      "Epoch: 11 | recon_loss: 9.505266189575195 | latent_loss: 102.4963150024414 | total_loss: 56.000789642333984\n",
      "Epoch: 12 | recon_loss: 9.41750717163086 | latent_loss: 96.5190200805664 | total_loss: 52.96826171875\n",
      "Epoch: 13 | recon_loss: 9.348968505859375 | latent_loss: 92.12901306152344 | total_loss: 50.738990783691406\n",
      "Epoch: 14 | recon_loss: 9.535665512084961 | latent_loss: 92.38191223144531 | total_loss: 50.95878982543945\n",
      "Epoch: 15 | recon_loss: 9.494246482849121 | latent_loss: 88.3471450805664 | total_loss: 48.92069625854492\n",
      "Epoch: 16 | recon_loss: 9.541189193725586 | latent_loss: 87.43527221679688 | total_loss: 48.48823165893555\n",
      "Epoch: 17 | recon_loss: 9.442256927490234 | latent_loss: 86.08501434326172 | total_loss: 47.763633728027344\n",
      "Epoch: 18 | recon_loss: 9.327688217163086 | latent_loss: 83.36808013916016 | total_loss: 46.34788513183594\n",
      "Epoch: 19 | recon_loss: 9.316486358642578 | latent_loss: 80.8814468383789 | total_loss: 45.098968505859375\n",
      "Epoch: 20 | recon_loss: 9.399356842041016 | latent_loss: 80.12305450439453 | total_loss: 44.761207580566406\n",
      "Epoch: 21 | recon_loss: 9.36107063293457 | latent_loss: 79.15786743164062 | total_loss: 44.25946807861328\n",
      "Epoch: 22 | recon_loss: 9.473756790161133 | latent_loss: 77.07040405273438 | total_loss: 43.27207946777344\n",
      "Epoch: 23 | recon_loss: 9.627888679504395 | latent_loss: 75.91378784179688 | total_loss: 42.77083969116211\n",
      "Epoch: 24 | recon_loss: 9.699556350708008 | latent_loss: 74.55278778076172 | total_loss: 42.12617111206055\n",
      "Epoch: 25 | recon_loss: 9.646257400512695 | latent_loss: 74.37006378173828 | total_loss: 42.00815963745117\n",
      "Epoch: 26 | recon_loss: 9.307183265686035 | latent_loss: 77.69029235839844 | total_loss: 43.49873733520508\n",
      "Epoch: 27 | recon_loss: 9.273733139038086 | latent_loss: 76.93012237548828 | total_loss: 43.1019287109375\n",
      "Epoch: 28 | recon_loss: 9.062881469726562 | latent_loss: 73.79635620117188 | total_loss: 41.42961883544922\n",
      "Epoch: 29 | recon_loss: 9.014413833618164 | latent_loss: 75.00253295898438 | total_loss: 42.00847244262695\n",
      "Epoch: 30 | recon_loss: 8.996557235717773 | latent_loss: 72.8340835571289 | total_loss: 40.915321350097656\n",
      "Epoch: 31 | recon_loss: 8.956565856933594 | latent_loss: 72.10873413085938 | total_loss: 40.532649993896484\n",
      "Epoch: 32 | recon_loss: 8.973492622375488 | latent_loss: 70.678955078125 | total_loss: 39.82622528076172\n",
      "Epoch: 33 | recon_loss: 8.374532699584961 | latent_loss: 88.70692443847656 | total_loss: 48.54072952270508\n",
      "Epoch: 34 | recon_loss: 8.43455696105957 | latent_loss: 84.90689086914062 | total_loss: 46.67072296142578\n",
      "Epoch: 35 | recon_loss: 8.522676467895508 | latent_loss: 75.64315032958984 | total_loss: 42.08291244506836\n",
      "Epoch: 36 | recon_loss: 8.66795539855957 | latent_loss: 71.19065856933594 | total_loss: 39.92930603027344\n",
      "Epoch: 37 | recon_loss: 8.821797370910645 | latent_loss: 68.48905181884766 | total_loss: 38.655426025390625\n",
      "Epoch: 38 | recon_loss: 8.905029296875 | latent_loss: 67.55471801757812 | total_loss: 38.22987365722656\n",
      "Epoch: 39 | recon_loss: 8.76274299621582 | latent_loss: 67.05619049072266 | total_loss: 37.90946578979492\n",
      "Epoch: 40 | recon_loss: 8.687217712402344 | latent_loss: 66.59671020507812 | total_loss: 37.641963958740234\n",
      "Epoch: 41 | recon_loss: 8.504207611083984 | latent_loss: 66.43368530273438 | total_loss: 37.46894836425781\n",
      "Epoch: 42 | recon_loss: 8.378660202026367 | latent_loss: 66.17034149169922 | total_loss: 37.27450180053711\n",
      "Epoch: 43 | recon_loss: 8.301227569580078 | latent_loss: 65.5072250366211 | total_loss: 36.90422821044922\n",
      "Epoch: 44 | recon_loss: 8.242152214050293 | latent_loss: 65.68912506103516 | total_loss: 36.96563720703125\n",
      "Epoch: 45 | recon_loss: 8.179502487182617 | latent_loss: 65.8628158569336 | total_loss: 37.02116012573242\n",
      "Epoch: 46 | recon_loss: 8.101985931396484 | latent_loss: 65.13929748535156 | total_loss: 36.620643615722656\n",
      "Epoch: 47 | recon_loss: 8.052652359008789 | latent_loss: 65.22805786132812 | total_loss: 36.64035415649414\n",
      "Epoch: 48 | recon_loss: 8.094568252563477 | latent_loss: 64.85126495361328 | total_loss: 36.47291564941406\n",
      "Epoch: 49 | recon_loss: 8.156291961669922 | latent_loss: 64.64244842529297 | total_loss: 36.39936828613281\n",
      "Epoch: 50 | recon_loss: 8.12510871887207 | latent_loss: 64.17369842529297 | total_loss: 36.1494026184082\n",
      "Epoch: 51 | recon_loss: 8.051058769226074 | latent_loss: 63.75526809692383 | total_loss: 35.90316390991211\n",
      "Epoch: 52 | recon_loss: 7.812942028045654 | latent_loss: 65.77027130126953 | total_loss: 36.79160690307617\n",
      "Epoch: 53 | recon_loss: 7.693401336669922 | latent_loss: 66.00273895263672 | total_loss: 36.84806823730469\n",
      "Epoch: 54 | recon_loss: 7.722752571105957 | latent_loss: 64.71863555908203 | total_loss: 36.22069549560547\n",
      "Epoch: 55 | recon_loss: 7.691224575042725 | latent_loss: 64.59122467041016 | total_loss: 36.1412239074707\n",
      "Epoch: 56 | recon_loss: 7.683407783508301 | latent_loss: 63.98984146118164 | total_loss: 35.83662414550781\n",
      "Epoch: 57 | recon_loss: 7.730311393737793 | latent_loss: 63.75498580932617 | total_loss: 35.74264907836914\n",
      "Epoch: 58 | recon_loss: 7.747430801391602 | latent_loss: 63.32703399658203 | total_loss: 35.5372314453125\n",
      "Epoch: 59 | recon_loss: 7.723834991455078 | latent_loss: 62.80647659301758 | total_loss: 35.26515579223633\n",
      "Epoch: 60 | recon_loss: 7.689687728881836 | latent_loss: 62.63197326660156 | total_loss: 35.160831451416016\n",
      "Epoch: 61 | recon_loss: 7.644970893859863 | latent_loss: 62.69085693359375 | total_loss: 35.16791534423828\n",
      "Epoch: 62 | recon_loss: 7.606046676635742 | latent_loss: 61.83788299560547 | total_loss: 34.72196578979492\n",
      "Epoch: 63 | recon_loss: 7.645430564880371 | latent_loss: 61.96825408935547 | total_loss: 34.80684280395508\n",
      "Epoch: 64 | recon_loss: 7.69867467880249 | latent_loss: 61.90212631225586 | total_loss: 34.80039978027344\n",
      "Epoch: 65 | recon_loss: 7.659332275390625 | latent_loss: 61.30069351196289 | total_loss: 34.480010986328125\n",
      "Epoch: 66 | recon_loss: 7.4870924949646 | latent_loss: 61.43946075439453 | total_loss: 34.46327590942383\n",
      "Epoch: 67 | recon_loss: 7.369174003601074 | latent_loss: 61.32948684692383 | total_loss: 34.34933090209961\n",
      "Epoch: 68 | recon_loss: 7.243706703186035 | latent_loss: 62.14136505126953 | total_loss: 34.692535400390625\n",
      "Epoch: 69 | recon_loss: 7.190499782562256 | latent_loss: 61.71525192260742 | total_loss: 34.452877044677734\n",
      "Epoch: 70 | recon_loss: 7.255198001861572 | latent_loss: 60.93970489501953 | total_loss: 34.097450256347656\n",
      "Epoch: 71 | recon_loss: 7.304869651794434 | latent_loss: 61.02559280395508 | total_loss: 34.16522979736328\n",
      "Epoch: 72 | recon_loss: 7.32306432723999 | latent_loss: 60.18633270263672 | total_loss: 33.75469970703125\n",
      "Epoch: 73 | recon_loss: 7.2862348556518555 | latent_loss: 60.08848571777344 | total_loss: 33.68735885620117\n",
      "Epoch: 74 | recon_loss: 7.329354763031006 | latent_loss: 59.82763671875 | total_loss: 33.578495025634766\n",
      "Epoch: 75 | recon_loss: 7.358012676239014 | latent_loss: 59.13620376586914 | total_loss: 33.247108459472656\n",
      "Epoch: 76 | recon_loss: 7.368422031402588 | latent_loss: 58.76622009277344 | total_loss: 33.06732177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | recon_loss: 7.326708793640137 | latent_loss: 58.84708023071289 | total_loss: 33.08689498901367\n",
      "Epoch: 78 | recon_loss: 7.200736045837402 | latent_loss: 58.17969512939453 | total_loss: 32.690216064453125\n",
      "Epoch: 79 | recon_loss: 7.144692420959473 | latent_loss: 58.46045684814453 | total_loss: 32.802574157714844\n",
      "Epoch: 80 | recon_loss: 7.075936317443848 | latent_loss: 57.90146255493164 | total_loss: 32.48870086669922\n",
      "Epoch: 81 | recon_loss: 7.044982433319092 | latent_loss: 57.99755096435547 | total_loss: 32.52126693725586\n",
      "Epoch: 82 | recon_loss: 7.121794700622559 | latent_loss: 57.35686492919922 | total_loss: 32.23933029174805\n",
      "Epoch: 83 | recon_loss: 7.216118335723877 | latent_loss: 56.8662109375 | total_loss: 32.04116439819336\n",
      "Epoch: 84 | recon_loss: 7.2723894119262695 | latent_loss: 56.64399337768555 | total_loss: 31.95819091796875\n",
      "Epoch: 85 | recon_loss: 7.243611812591553 | latent_loss: 56.26872253417969 | total_loss: 31.756166458129883\n",
      "Epoch: 86 | recon_loss: 7.159668922424316 | latent_loss: 56.10867691040039 | total_loss: 31.634172439575195\n",
      "Epoch: 87 | recon_loss: 7.094115257263184 | latent_loss: 55.49385070800781 | total_loss: 31.293983459472656\n",
      "Epoch: 88 | recon_loss: 7.070080280303955 | latent_loss: 55.3073616027832 | total_loss: 31.188720703125\n",
      "Epoch: 89 | recon_loss: 6.960820198059082 | latent_loss: 55.37809753417969 | total_loss: 31.169458389282227\n",
      "Epoch: 90 | recon_loss: 6.926537036895752 | latent_loss: 54.83069610595703 | total_loss: 30.878616333007812\n",
      "Epoch: 91 | recon_loss: 6.947273254394531 | latent_loss: 54.97951889038086 | total_loss: 30.963396072387695\n",
      "Epoch: 92 | recon_loss: 6.946046829223633 | latent_loss: 55.04613494873047 | total_loss: 30.996089935302734\n",
      "Epoch: 93 | recon_loss: 7.013989448547363 | latent_loss: 54.67978286743164 | total_loss: 30.846885681152344\n",
      "Epoch: 94 | recon_loss: 6.965980529785156 | latent_loss: 55.03278350830078 | total_loss: 30.99938201904297\n",
      "Epoch: 95 | recon_loss: 6.951440811157227 | latent_loss: 54.2935676574707 | total_loss: 30.62250518798828\n",
      "Epoch: 96 | recon_loss: 6.968177795410156 | latent_loss: 53.78477478027344 | total_loss: 30.376476287841797\n",
      "Epoch: 97 | recon_loss: 7.031555652618408 | latent_loss: 53.365753173828125 | total_loss: 30.198654174804688\n",
      "Epoch: 98 | recon_loss: 7.427727699279785 | latent_loss: 53.4310302734375 | total_loss: 30.429378509521484\n",
      "Epoch: 99 | recon_loss: 7.714215278625488 | latent_loss: 52.92100524902344 | total_loss: 30.317609786987305\n",
      "Epoch: 100 | recon_loss: 7.656040191650391 | latent_loss: 52.68424606323242 | total_loss: 30.170143127441406\n",
      "Epoch: 101 | recon_loss: 7.125877857208252 | latent_loss: 59.99132537841797 | total_loss: 33.55860137939453\n",
      "Epoch: 102 | recon_loss: 6.600809097290039 | latent_loss: 57.00649642944336 | total_loss: 31.803653717041016\n",
      "Epoch: 103 | recon_loss: 6.811550140380859 | latent_loss: 56.509883880615234 | total_loss: 31.660717010498047\n",
      "Epoch: 104 | recon_loss: 7.096159934997559 | latent_loss: 57.77545928955078 | total_loss: 32.43581008911133\n",
      "Epoch: 105 | recon_loss: 7.293926239013672 | latent_loss: 53.635108947753906 | total_loss: 30.46451759338379\n",
      "Epoch: 106 | recon_loss: 7.399879455566406 | latent_loss: 53.46171569824219 | total_loss: 30.430797576904297\n",
      "Epoch: 107 | recon_loss: 7.161372661590576 | latent_loss: 58.94166946411133 | total_loss: 33.05152130126953\n",
      "Epoch: 108 | recon_loss: 6.837839126586914 | latent_loss: 63.67115783691406 | total_loss: 35.25449752807617\n",
      "Epoch: 109 | recon_loss: 6.948060035705566 | latent_loss: 58.62580871582031 | total_loss: 32.78693389892578\n",
      "Epoch: 110 | recon_loss: 7.263797283172607 | latent_loss: 56.14677429199219 | total_loss: 31.705286026000977\n",
      "Epoch: 111 | recon_loss: 7.296998023986816 | latent_loss: 54.2838249206543 | total_loss: 30.7904109954834\n",
      "Epoch: 112 | recon_loss: 7.360050678253174 | latent_loss: 53.67849349975586 | total_loss: 30.519271850585938\n",
      "Epoch: 113 | recon_loss: 7.443725109100342 | latent_loss: 52.67579650878906 | total_loss: 30.05976104736328\n",
      "Epoch: 114 | recon_loss: 7.332609176635742 | latent_loss: 52.63751983642578 | total_loss: 29.985065460205078\n",
      "Epoch: 115 | recon_loss: 7.262015342712402 | latent_loss: 51.72674560546875 | total_loss: 29.494380950927734\n",
      "Epoch: 116 | recon_loss: 7.1068620681762695 | latent_loss: 51.60019302368164 | total_loss: 29.353527069091797\n",
      "Epoch: 117 | recon_loss: 6.964748382568359 | latent_loss: 51.58498764038086 | total_loss: 29.27486801147461\n",
      "Epoch: 118 | recon_loss: 6.990352630615234 | latent_loss: 51.039222717285156 | total_loss: 29.014787673950195\n",
      "Epoch: 119 | recon_loss: 7.034717082977295 | latent_loss: 50.60478210449219 | total_loss: 28.81974983215332\n",
      "Epoch: 120 | recon_loss: 7.122765064239502 | latent_loss: 50.49382781982422 | total_loss: 28.80829620361328\n",
      "Epoch: 121 | recon_loss: 7.313852310180664 | latent_loss: 50.3559455871582 | total_loss: 28.83489990234375\n",
      "Epoch: 122 | recon_loss: 7.11381721496582 | latent_loss: 50.24462127685547 | total_loss: 28.679218292236328\n",
      "Epoch: 123 | recon_loss: 7.0620012283325195 | latent_loss: 50.39314270019531 | total_loss: 28.727571487426758\n",
      "Epoch: 124 | recon_loss: 7.122937202453613 | latent_loss: 49.3901481628418 | total_loss: 28.256542205810547\n",
      "Epoch: 125 | recon_loss: 7.177483558654785 | latent_loss: 49.33150100708008 | total_loss: 28.254491806030273\n",
      "Epoch: 126 | recon_loss: 7.152100563049316 | latent_loss: 49.74414825439453 | total_loss: 28.448123931884766\n",
      "Epoch: 127 | recon_loss: 7.0967116355896 | latent_loss: 49.698585510253906 | total_loss: 28.397647857666016\n",
      "Epoch: 128 | recon_loss: 7.2014007568359375 | latent_loss: 48.78043746948242 | total_loss: 27.99091911315918\n",
      "Epoch: 129 | recon_loss: 7.250591278076172 | latent_loss: 48.04093933105469 | total_loss: 27.64576530456543\n",
      "Epoch: 130 | recon_loss: 7.264760971069336 | latent_loss: 47.94327163696289 | total_loss: 27.604015350341797\n",
      "Epoch: 131 | recon_loss: 7.336330413818359 | latent_loss: 47.54340744018555 | total_loss: 27.439868927001953\n",
      "Epoch: 132 | recon_loss: 7.454019546508789 | latent_loss: 47.141422271728516 | total_loss: 27.29772186279297\n",
      "Epoch: 133 | recon_loss: 7.566350936889648 | latent_loss: 46.51073455810547 | total_loss: 27.038543701171875\n",
      "Epoch: 134 | recon_loss: 7.5375518798828125 | latent_loss: 46.402076721191406 | total_loss: 26.96981430053711\n",
      "Epoch: 135 | recon_loss: 7.523713111877441 | latent_loss: 46.209495544433594 | total_loss: 26.86660385131836\n",
      "Epoch: 136 | recon_loss: 7.482954025268555 | latent_loss: 45.15702438354492 | total_loss: 26.319988250732422\n",
      "Epoch: 137 | recon_loss: 7.433586597442627 | latent_loss: 45.522239685058594 | total_loss: 26.47791290283203\n",
      "Epoch: 138 | recon_loss: 7.300238609313965 | latent_loss: 45.842369079589844 | total_loss: 26.571304321289062\n",
      "Epoch: 139 | recon_loss: 7.113432884216309 | latent_loss: 45.424442291259766 | total_loss: 26.268938064575195\n",
      "Epoch: 140 | recon_loss: 7.219695091247559 | latent_loss: 53.09302520751953 | total_loss: 30.156360626220703\n",
      "Epoch: 141 | recon_loss: 7.057618141174316 | latent_loss: 55.05030059814453 | total_loss: 31.053958892822266\n",
      "Epoch: 142 | recon_loss: 7.444545745849609 | latent_loss: 49.3605842590332 | total_loss: 28.402565002441406\n",
      "Epoch: 143 | recon_loss: 7.570626258850098 | latent_loss: 47.53295135498047 | total_loss: 27.551788330078125\n",
      "Epoch: 144 | recon_loss: 7.62178897857666 | latent_loss: 46.29469680786133 | total_loss: 26.958242416381836\n",
      "Epoch: 145 | recon_loss: 7.686826229095459 | latent_loss: 45.33437728881836 | total_loss: 26.510601043701172\n",
      "Epoch: 146 | recon_loss: 7.630382537841797 | latent_loss: 44.63742446899414 | total_loss: 26.13390350341797\n",
      "Epoch: 147 | recon_loss: 7.624710559844971 | latent_loss: 43.78779983520508 | total_loss: 25.706254959106445\n",
      "Epoch: 148 | recon_loss: 7.442835807800293 | latent_loss: 44.532814025878906 | total_loss: 25.987825393676758\n",
      "Epoch: 149 | recon_loss: 7.474452972412109 | latent_loss: 44.08377456665039 | total_loss: 25.77911376953125\n",
      "Epoch: 150 | recon_loss: 7.556047439575195 | latent_loss: 43.70317077636719 | total_loss: 25.629608154296875\n",
      "Epoch: 151 | recon_loss: 7.986597537994385 | latent_loss: 43.80183410644531 | total_loss: 25.894216537475586\n",
      "Epoch: 152 | recon_loss: 8.05089282989502 | latent_loss: 43.02681350708008 | total_loss: 25.53885269165039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153 | recon_loss: 7.806715488433838 | latent_loss: 42.773529052734375 | total_loss: 25.290122985839844\n",
      "Epoch: 154 | recon_loss: 7.55719518661499 | latent_loss: 42.09360885620117 | total_loss: 24.825401306152344\n",
      "Epoch: 155 | recon_loss: 7.42028284072876 | latent_loss: 42.41178894042969 | total_loss: 24.91603660583496\n",
      "Epoch: 156 | recon_loss: 7.340177536010742 | latent_loss: 41.63578796386719 | total_loss: 24.48798370361328\n",
      "Epoch: 157 | recon_loss: 7.301215648651123 | latent_loss: 41.8582878112793 | total_loss: 24.57975196838379\n",
      "Epoch: 158 | recon_loss: 7.361329555511475 | latent_loss: 41.97218322753906 | total_loss: 24.66675567626953\n",
      "Epoch: 159 | recon_loss: 7.628974914550781 | latent_loss: 41.93886947631836 | total_loss: 24.78392219543457\n",
      "Epoch: 160 | recon_loss: 7.717194080352783 | latent_loss: 41.13970184326172 | total_loss: 24.428447723388672\n",
      "Epoch: 161 | recon_loss: 7.72283935546875 | latent_loss: 41.121253967285156 | total_loss: 24.422046661376953\n",
      "Epoch: 162 | recon_loss: 7.624687194824219 | latent_loss: 41.016075134277344 | total_loss: 24.32038116455078\n",
      "Epoch: 163 | recon_loss: 7.483288764953613 | latent_loss: 41.49394226074219 | total_loss: 24.488615036010742\n",
      "Epoch: 164 | recon_loss: 7.577495574951172 | latent_loss: 41.13954544067383 | total_loss: 24.3585205078125\n",
      "Epoch: 165 | recon_loss: 7.621089935302734 | latent_loss: 40.786991119384766 | total_loss: 24.20404052734375\n",
      "Epoch: 166 | recon_loss: 7.589991092681885 | latent_loss: 39.702327728271484 | total_loss: 23.646160125732422\n",
      "Epoch: 167 | recon_loss: 7.5410003662109375 | latent_loss: 39.57648468017578 | total_loss: 23.55874252319336\n",
      "Epoch: 168 | recon_loss: 7.623924255371094 | latent_loss: 39.458824157714844 | total_loss: 23.54137420654297\n",
      "Epoch: 169 | recon_loss: 7.608287811279297 | latent_loss: 39.45461654663086 | total_loss: 23.531452178955078\n",
      "Epoch: 170 | recon_loss: 7.645589351654053 | latent_loss: 39.08558654785156 | total_loss: 23.36558723449707\n",
      "Epoch: 171 | recon_loss: 7.502100944519043 | latent_loss: 39.15637969970703 | total_loss: 23.329240798950195\n",
      "Epoch: 172 | recon_loss: 7.558503150939941 | latent_loss: 41.69286346435547 | total_loss: 24.625682830810547\n",
      "Epoch: 173 | recon_loss: 7.502168655395508 | latent_loss: 39.70100784301758 | total_loss: 23.60158920288086\n",
      "Epoch: 174 | recon_loss: 7.331692695617676 | latent_loss: 40.00442123413086 | total_loss: 23.66805648803711\n",
      "Epoch: 175 | recon_loss: 7.222489833831787 | latent_loss: 39.32188415527344 | total_loss: 23.272186279296875\n",
      "Epoch: 176 | recon_loss: 7.107673168182373 | latent_loss: 39.00261306762695 | total_loss: 23.055143356323242\n",
      "Epoch: 177 | recon_loss: 6.9293036460876465 | latent_loss: 38.64056396484375 | total_loss: 22.78493309020996\n",
      "Epoch: 178 | recon_loss: 6.753538131713867 | latent_loss: 39.905540466308594 | total_loss: 23.329540252685547\n",
      "Epoch: 179 | recon_loss: 6.837263107299805 | latent_loss: 39.19453430175781 | total_loss: 23.015899658203125\n",
      "Epoch: 180 | recon_loss: 6.919793605804443 | latent_loss: 39.07419967651367 | total_loss: 22.99699592590332\n",
      "Epoch: 181 | recon_loss: 7.001584053039551 | latent_loss: 38.37977981567383 | total_loss: 22.69068145751953\n",
      "Epoch: 182 | recon_loss: 7.007775783538818 | latent_loss: 38.085296630859375 | total_loss: 22.54653549194336\n",
      "Epoch: 183 | recon_loss: 6.991674423217773 | latent_loss: 38.42710876464844 | total_loss: 22.709392547607422\n",
      "Epoch: 184 | recon_loss: 6.607867240905762 | latent_loss: 41.60554504394531 | total_loss: 24.106706619262695\n",
      "Epoch: 185 | recon_loss: 6.68931770324707 | latent_loss: 40.89700698852539 | total_loss: 23.793163299560547\n",
      "Epoch: 186 | recon_loss: 6.883405685424805 | latent_loss: 39.48021697998047 | total_loss: 23.181812286376953\n",
      "Epoch: 187 | recon_loss: 7.154208183288574 | latent_loss: 38.64918518066406 | total_loss: 22.901697158813477\n",
      "Epoch: 188 | recon_loss: 7.251216411590576 | latent_loss: 37.929874420166016 | total_loss: 22.590545654296875\n",
      "Epoch: 189 | recon_loss: 7.283465385437012 | latent_loss: 37.46711730957031 | total_loss: 22.37529182434082\n",
      "Epoch: 190 | recon_loss: 7.336451530456543 | latent_loss: 37.34538650512695 | total_loss: 22.340919494628906\n",
      "Epoch: 191 | recon_loss: 7.324943542480469 | latent_loss: 37.17493438720703 | total_loss: 22.24993896484375\n",
      "Epoch: 192 | recon_loss: 7.3564133644104 | latent_loss: 36.98224639892578 | total_loss: 22.169330596923828\n",
      "Epoch: 193 | recon_loss: 7.356452941894531 | latent_loss: 37.08982849121094 | total_loss: 22.223140716552734\n",
      "Epoch: 194 | recon_loss: 7.32486629486084 | latent_loss: 36.542171478271484 | total_loss: 21.93351936340332\n",
      "Epoch: 195 | recon_loss: 7.1415910720825195 | latent_loss: 42.84360885620117 | total_loss: 24.992599487304688\n",
      "Epoch: 196 | recon_loss: 6.941720962524414 | latent_loss: 44.34790802001953 | total_loss: 25.644813537597656\n",
      "Epoch: 197 | recon_loss: 6.523892879486084 | latent_loss: 42.34320068359375 | total_loss: 24.43354606628418\n",
      "Epoch: 198 | recon_loss: 6.459589958190918 | latent_loss: 40.84343719482422 | total_loss: 23.651514053344727\n",
      "Epoch: 199 | recon_loss: 6.538734436035156 | latent_loss: 39.33605194091797 | total_loss: 22.937393188476562\n",
      "Epoch: 200 | recon_loss: 6.662168502807617 | latent_loss: 38.352294921875 | total_loss: 22.507232666015625\n",
      "Epoch: 201 | recon_loss: 6.632464408874512 | latent_loss: 38.04512023925781 | total_loss: 22.33879280090332\n",
      "Epoch: 202 | recon_loss: 6.695217609405518 | latent_loss: 37.73998260498047 | total_loss: 22.217599868774414\n",
      "Epoch: 203 | recon_loss: 6.699883937835693 | latent_loss: 37.1307258605957 | total_loss: 21.91530418395996\n",
      "Epoch: 204 | recon_loss: 6.774410724639893 | latent_loss: 37.48557662963867 | total_loss: 22.129993438720703\n",
      "Epoch: 205 | recon_loss: 6.879727363586426 | latent_loss: 36.81755447387695 | total_loss: 21.84864044189453\n",
      "Epoch: 206 | recon_loss: 6.879797458648682 | latent_loss: 36.87111282348633 | total_loss: 21.875455856323242\n",
      "Epoch: 207 | recon_loss: 6.868619918823242 | latent_loss: 36.71490478515625 | total_loss: 21.791763305664062\n",
      "Epoch: 208 | recon_loss: 6.833198547363281 | latent_loss: 36.37943649291992 | total_loss: 21.6063175201416\n",
      "Epoch: 209 | recon_loss: 6.828945636749268 | latent_loss: 36.61845397949219 | total_loss: 21.72369956970215\n",
      "Epoch: 210 | recon_loss: 6.875792503356934 | latent_loss: 36.11349868774414 | total_loss: 21.494646072387695\n",
      "Epoch: 211 | recon_loss: 6.688848495483398 | latent_loss: 36.23143768310547 | total_loss: 21.46014404296875\n",
      "Epoch: 212 | recon_loss: 6.716701507568359 | latent_loss: 36.74211883544922 | total_loss: 21.72941017150879\n",
      "Epoch: 213 | recon_loss: 6.794777870178223 | latent_loss: 36.64459228515625 | total_loss: 21.719684600830078\n",
      "Epoch: 214 | recon_loss: 6.875744819641113 | latent_loss: 36.3743782043457 | total_loss: 21.62506103515625\n",
      "Epoch: 215 | recon_loss: 6.927915573120117 | latent_loss: 36.10716247558594 | total_loss: 21.517539978027344\n",
      "Epoch: 216 | recon_loss: 6.918959140777588 | latent_loss: 35.898380279541016 | total_loss: 21.40867042541504\n",
      "Epoch: 217 | recon_loss: 6.928842544555664 | latent_loss: 35.88984680175781 | total_loss: 21.409343719482422\n",
      "Epoch: 218 | recon_loss: 6.9169793128967285 | latent_loss: 36.18550109863281 | total_loss: 21.551240921020508\n",
      "Epoch: 219 | recon_loss: 7.106353282928467 | latent_loss: 39.37386703491211 | total_loss: 23.240110397338867\n",
      "Epoch: 220 | recon_loss: 7.009786128997803 | latent_loss: 41.34287643432617 | total_loss: 24.17633056640625\n",
      "Epoch: 221 | recon_loss: 6.981488227844238 | latent_loss: 40.93050003051758 | total_loss: 23.95599365234375\n",
      "Epoch: 222 | recon_loss: 6.919665336608887 | latent_loss: 40.75162124633789 | total_loss: 23.835643768310547\n",
      "Epoch: 223 | recon_loss: 6.958742141723633 | latent_loss: 38.6236572265625 | total_loss: 22.79119873046875\n",
      "Epoch: 224 | recon_loss: 6.660622596740723 | latent_loss: 37.61102294921875 | total_loss: 22.135822296142578\n",
      "Epoch: 225 | recon_loss: 6.647225379943848 | latent_loss: 37.64997100830078 | total_loss: 22.148597717285156\n",
      "Epoch: 226 | recon_loss: 6.531176567077637 | latent_loss: 37.09440612792969 | total_loss: 21.81279182434082\n",
      "Epoch: 227 | recon_loss: 6.835771083831787 | latent_loss: 36.98723220825195 | total_loss: 21.911500930786133\n",
      "Epoch: 228 | recon_loss: 7.013579845428467 | latent_loss: 36.63605499267578 | total_loss: 21.824817657470703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 229 | recon_loss: 7.083232402801514 | latent_loss: 36.107025146484375 | total_loss: 21.595129013061523\n",
      "Epoch: 230 | recon_loss: 7.335671901702881 | latent_loss: 35.687191009521484 | total_loss: 21.511430740356445\n",
      "Epoch: 231 | recon_loss: 7.47884464263916 | latent_loss: 35.8489990234375 | total_loss: 21.663921356201172\n",
      "Epoch: 232 | recon_loss: 7.332554340362549 | latent_loss: 35.15563201904297 | total_loss: 21.24409294128418\n",
      "Epoch: 233 | recon_loss: 6.998517036437988 | latent_loss: 35.8162841796875 | total_loss: 21.407400131225586\n",
      "Epoch: 234 | recon_loss: 6.670361518859863 | latent_loss: 37.33653259277344 | total_loss: 22.003446578979492\n",
      "Epoch: 235 | recon_loss: 6.622868537902832 | latent_loss: 37.500526428222656 | total_loss: 22.061697006225586\n",
      "Epoch: 236 | recon_loss: 6.613470554351807 | latent_loss: 36.29762268066406 | total_loss: 21.455547332763672\n",
      "Epoch: 237 | recon_loss: 6.706913948059082 | latent_loss: 35.61905288696289 | total_loss: 21.162982940673828\n",
      "Epoch: 238 | recon_loss: 6.814436912536621 | latent_loss: 35.501983642578125 | total_loss: 21.15821075439453\n",
      "Epoch: 239 | recon_loss: 6.913792610168457 | latent_loss: 35.20161437988281 | total_loss: 21.057703018188477\n",
      "Epoch: 240 | recon_loss: 6.895908832550049 | latent_loss: 35.27925109863281 | total_loss: 21.08757972717285\n",
      "Epoch: 241 | recon_loss: 6.829774856567383 | latent_loss: 34.98756408691406 | total_loss: 20.908668518066406\n",
      "Epoch: 242 | recon_loss: 6.806256294250488 | latent_loss: 34.965885162353516 | total_loss: 20.886070251464844\n",
      "Epoch: 243 | recon_loss: 6.922515869140625 | latent_loss: 35.10609436035156 | total_loss: 21.014305114746094\n",
      "Epoch: 244 | recon_loss: 6.793885231018066 | latent_loss: 35.06038284301758 | total_loss: 20.927133560180664\n",
      "Epoch: 245 | recon_loss: 6.644599914550781 | latent_loss: 35.42315673828125 | total_loss: 21.033878326416016\n",
      "Epoch: 246 | recon_loss: 6.658559322357178 | latent_loss: 35.321537017822266 | total_loss: 20.990047454833984\n",
      "Epoch: 247 | recon_loss: 6.720935821533203 | latent_loss: 34.78759002685547 | total_loss: 20.754262924194336\n",
      "Epoch: 248 | recon_loss: 6.847512722015381 | latent_loss: 34.73707962036133 | total_loss: 20.792295455932617\n",
      "Epoch: 249 | recon_loss: 6.949223518371582 | latent_loss: 34.76487350463867 | total_loss: 20.85704803466797\n",
      "Epoch: 250 | recon_loss: 6.905921936035156 | latent_loss: 34.80826950073242 | total_loss: 20.85709571838379\n",
      "Epoch: 251 | recon_loss: 6.766112804412842 | latent_loss: 34.686500549316406 | total_loss: 20.726306915283203\n",
      "Epoch: 252 | recon_loss: 6.753290176391602 | latent_loss: 34.69828796386719 | total_loss: 20.725788116455078\n",
      "Epoch: 253 | recon_loss: 6.860504150390625 | latent_loss: 34.26898956298828 | total_loss: 20.564746856689453\n",
      "Epoch: 254 | recon_loss: 6.449479103088379 | latent_loss: 35.612693786621094 | total_loss: 21.031085968017578\n",
      "Epoch: 255 | recon_loss: 6.260082244873047 | latent_loss: 36.594635009765625 | total_loss: 21.427358627319336\n",
      "Epoch: 256 | recon_loss: 6.086031913757324 | latent_loss: 38.255149841308594 | total_loss: 22.170591354370117\n",
      "Epoch: 257 | recon_loss: 6.287322044372559 | latent_loss: 37.07121276855469 | total_loss: 21.67926788330078\n",
      "Epoch: 258 | recon_loss: 6.487248420715332 | latent_loss: 35.6234016418457 | total_loss: 21.05532455444336\n",
      "Epoch: 259 | recon_loss: 6.664965629577637 | latent_loss: 34.982059478759766 | total_loss: 20.82351303100586\n",
      "Epoch: 260 | recon_loss: 6.715452194213867 | latent_loss: 34.80202102661133 | total_loss: 20.75873565673828\n",
      "Epoch: 261 | recon_loss: 6.625716686248779 | latent_loss: 35.91053009033203 | total_loss: 21.268123626708984\n",
      "Epoch: 262 | recon_loss: 6.656771659851074 | latent_loss: 35.65501403808594 | total_loss: 21.155893325805664\n",
      "Epoch: 263 | recon_loss: 6.613606929779053 | latent_loss: 35.15840530395508 | total_loss: 20.886005401611328\n",
      "Epoch: 264 | recon_loss: 6.560217380523682 | latent_loss: 34.986873626708984 | total_loss: 20.77354621887207\n",
      "Epoch: 265 | recon_loss: 6.9137983322143555 | latent_loss: 36.60089874267578 | total_loss: 21.757349014282227\n",
      "Epoch: 266 | recon_loss: 7.266498565673828 | latent_loss: 55.77653121948242 | total_loss: 31.521514892578125\n",
      "Epoch: 267 | recon_loss: 7.087725639343262 | latent_loss: 60.80282211303711 | total_loss: 33.945274353027344\n",
      "Epoch: 268 | recon_loss: 7.422213554382324 | latent_loss: 45.11497497558594 | total_loss: 26.26859474182129\n",
      "Epoch: 269 | recon_loss: 7.535625457763672 | latent_loss: 41.66280746459961 | total_loss: 24.59921646118164\n",
      "Epoch: 270 | recon_loss: 7.694074630737305 | latent_loss: 40.54137420654297 | total_loss: 24.117725372314453\n",
      "Epoch: 271 | recon_loss: 7.485260963439941 | latent_loss: 39.49991989135742 | total_loss: 23.492589950561523\n",
      "Epoch: 272 | recon_loss: 7.367982864379883 | latent_loss: 37.61709976196289 | total_loss: 22.492542266845703\n",
      "Epoch: 273 | recon_loss: 7.276873588562012 | latent_loss: 36.91946792602539 | total_loss: 22.09817123413086\n",
      "Epoch: 274 | recon_loss: 7.19272518157959 | latent_loss: 36.36906051635742 | total_loss: 21.780893325805664\n",
      "Epoch: 275 | recon_loss: 7.12558650970459 | latent_loss: 35.98826599121094 | total_loss: 21.556926727294922\n",
      "Epoch: 276 | recon_loss: 7.06092643737793 | latent_loss: 35.91658020019531 | total_loss: 21.488754272460938\n",
      "Epoch: 277 | recon_loss: 6.987004280090332 | latent_loss: 36.09677505493164 | total_loss: 21.541889190673828\n",
      "Epoch: 278 | recon_loss: 7.111599445343018 | latent_loss: 35.790409088134766 | total_loss: 21.451004028320312\n",
      "Epoch: 279 | recon_loss: 6.586440086364746 | latent_loss: 36.72636795043945 | total_loss: 21.656404495239258\n",
      "Epoch: 280 | recon_loss: 6.482122421264648 | latent_loss: 36.97499084472656 | total_loss: 21.728557586669922\n",
      "Epoch: 281 | recon_loss: 6.587296009063721 | latent_loss: 36.46555709838867 | total_loss: 21.526426315307617\n",
      "Epoch: 282 | recon_loss: 6.768877029418945 | latent_loss: 35.712677001953125 | total_loss: 21.24077606201172\n",
      "Epoch: 283 | recon_loss: 6.948078155517578 | latent_loss: 35.089012145996094 | total_loss: 21.018545150756836\n",
      "Epoch: 284 | recon_loss: 7.007165431976318 | latent_loss: 34.98765563964844 | total_loss: 20.99740982055664\n",
      "Epoch: 285 | recon_loss: 7.007481098175049 | latent_loss: 34.67206573486328 | total_loss: 20.839773178100586\n",
      "Epoch: 286 | recon_loss: 7.007387161254883 | latent_loss: 34.93137741088867 | total_loss: 20.969383239746094\n",
      "Epoch: 287 | recon_loss: 7.093559265136719 | latent_loss: 34.71030807495117 | total_loss: 20.901933670043945\n",
      "Epoch: 288 | recon_loss: 7.050705909729004 | latent_loss: 34.946170806884766 | total_loss: 20.998437881469727\n",
      "Epoch: 289 | recon_loss: 7.140331268310547 | latent_loss: 34.79463195800781 | total_loss: 20.96748161315918\n",
      "Epoch: 290 | recon_loss: 7.060943603515625 | latent_loss: 37.59605407714844 | total_loss: 22.32849884033203\n",
      "Epoch: 291 | recon_loss: 6.898567199707031 | latent_loss: 37.86284637451172 | total_loss: 22.380706787109375\n",
      "Epoch: 292 | recon_loss: 6.794033050537109 | latent_loss: 36.41653060913086 | total_loss: 21.605281829833984\n",
      "Epoch: 293 | recon_loss: 6.944617748260498 | latent_loss: 35.99087142944336 | total_loss: 21.467744827270508\n",
      "Epoch: 294 | recon_loss: 7.058267593383789 | latent_loss: 35.48646926879883 | total_loss: 21.272369384765625\n",
      "Epoch: 295 | recon_loss: 7.142122268676758 | latent_loss: 35.06428527832031 | total_loss: 21.10320281982422\n",
      "Epoch: 296 | recon_loss: 7.205869197845459 | latent_loss: 35.26161193847656 | total_loss: 21.233739852905273\n",
      "Epoch: 297 | recon_loss: 7.283932685852051 | latent_loss: 35.678653717041016 | total_loss: 21.481292724609375\n",
      "Epoch: 298 | recon_loss: 7.310243606567383 | latent_loss: 35.10783386230469 | total_loss: 21.20903778076172\n",
      "Epoch: 299 | recon_loss: 7.283987998962402 | latent_loss: 35.06275177001953 | total_loss: 21.173370361328125\n",
      "Epoch: 300 | recon_loss: 7.302196979522705 | latent_loss: 34.69054412841797 | total_loss: 20.996370315551758\n",
      "Epoch: 301 | recon_loss: 7.467232704162598 | latent_loss: 34.24559020996094 | total_loss: 20.85641098022461\n",
      "Epoch: 302 | recon_loss: 7.556042671203613 | latent_loss: 34.052955627441406 | total_loss: 20.80449867248535\n",
      "Epoch: 303 | recon_loss: 7.582467079162598 | latent_loss: 33.942230224609375 | total_loss: 20.762348175048828\n",
      "Epoch: 304 | recon_loss: 7.631587982177734 | latent_loss: 33.72673034667969 | total_loss: 20.67915916442871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 305 | recon_loss: 7.552555084228516 | latent_loss: 33.573307037353516 | total_loss: 20.562931060791016\n",
      "Epoch: 306 | recon_loss: 7.46260929107666 | latent_loss: 33.69036865234375 | total_loss: 20.576488494873047\n",
      "Epoch: 307 | recon_loss: 7.380215644836426 | latent_loss: 33.28769302368164 | total_loss: 20.333953857421875\n",
      "Epoch: 308 | recon_loss: 7.338227272033691 | latent_loss: 33.757076263427734 | total_loss: 20.547651290893555\n",
      "Epoch: 309 | recon_loss: 7.370543479919434 | latent_loss: 33.79491424560547 | total_loss: 20.58272933959961\n",
      "Epoch: 310 | recon_loss: 7.212192058563232 | latent_loss: 36.28376770019531 | total_loss: 21.74798011779785\n",
      "Epoch: 311 | recon_loss: 7.214406967163086 | latent_loss: 35.516754150390625 | total_loss: 21.365581512451172\n",
      "Epoch: 312 | recon_loss: 7.149182319641113 | latent_loss: 34.200138092041016 | total_loss: 20.674659729003906\n",
      "Epoch: 313 | recon_loss: 7.107929229736328 | latent_loss: 33.92538070678711 | total_loss: 20.51665496826172\n",
      "Epoch: 314 | recon_loss: 7.088916778564453 | latent_loss: 34.258419036865234 | total_loss: 20.673667907714844\n",
      "Epoch: 315 | recon_loss: 7.047272205352783 | latent_loss: 33.61494445800781 | total_loss: 20.33110809326172\n",
      "Epoch: 316 | recon_loss: 7.138242721557617 | latent_loss: 34.22248077392578 | total_loss: 20.680362701416016\n",
      "Epoch: 317 | recon_loss: 6.910736083984375 | latent_loss: 34.905067443847656 | total_loss: 20.907901763916016\n",
      "Epoch: 318 | recon_loss: 6.866631031036377 | latent_loss: 34.89555740356445 | total_loss: 20.881093978881836\n",
      "Epoch: 319 | recon_loss: 6.899634838104248 | latent_loss: 34.68373489379883 | total_loss: 20.791685104370117\n",
      "Epoch: 320 | recon_loss: 6.945184707641602 | latent_loss: 33.66740798950195 | total_loss: 20.306297302246094\n",
      "Epoch: 321 | recon_loss: 6.936576843261719 | latent_loss: 34.268028259277344 | total_loss: 20.60230255126953\n",
      "Epoch: 322 | recon_loss: 6.965047836303711 | latent_loss: 34.160011291503906 | total_loss: 20.562530517578125\n",
      "Epoch: 323 | recon_loss: 7.023113250732422 | latent_loss: 33.525814056396484 | total_loss: 20.274463653564453\n",
      "Epoch: 324 | recon_loss: 7.07448148727417 | latent_loss: 33.06013870239258 | total_loss: 20.067310333251953\n",
      "Epoch: 325 | recon_loss: 7.084193229675293 | latent_loss: 33.49162292480469 | total_loss: 20.28790855407715\n",
      "Epoch: 326 | recon_loss: 7.0525665283203125 | latent_loss: 33.213165283203125 | total_loss: 20.13286590576172\n",
      "Epoch: 327 | recon_loss: 7.044870376586914 | latent_loss: 33.24687957763672 | total_loss: 20.1458740234375\n",
      "Epoch: 328 | recon_loss: 7.026813507080078 | latent_loss: 33.08578109741211 | total_loss: 20.056297302246094\n",
      "Epoch: 329 | recon_loss: 6.980685234069824 | latent_loss: 33.96568298339844 | total_loss: 20.47318458557129\n",
      "Epoch: 330 | recon_loss: 7.063773155212402 | latent_loss: 35.80112838745117 | total_loss: 21.432451248168945\n",
      "Epoch: 331 | recon_loss: 6.959733963012695 | latent_loss: 34.65025329589844 | total_loss: 20.80499267578125\n",
      "Epoch: 332 | recon_loss: 6.8541035652160645 | latent_loss: 34.1086311340332 | total_loss: 20.481367111206055\n",
      "Epoch: 333 | recon_loss: 6.772833824157715 | latent_loss: 34.148193359375 | total_loss: 20.460514068603516\n",
      "Epoch: 334 | recon_loss: 6.697282314300537 | latent_loss: 33.84346389770508 | total_loss: 20.27037239074707\n",
      "Epoch: 335 | recon_loss: 6.988791465759277 | latent_loss: 34.76231002807617 | total_loss: 20.875551223754883\n",
      "Epoch: 336 | recon_loss: 7.04628849029541 | latent_loss: 34.14794921875 | total_loss: 20.597118377685547\n",
      "Epoch: 337 | recon_loss: 6.8855881690979 | latent_loss: 33.89143371582031 | total_loss: 20.388511657714844\n",
      "Epoch: 338 | recon_loss: 6.779521942138672 | latent_loss: 33.71013641357422 | total_loss: 20.244829177856445\n",
      "Epoch: 339 | recon_loss: 6.6253132820129395 | latent_loss: 33.48008346557617 | total_loss: 20.052698135375977\n",
      "Epoch: 340 | recon_loss: 6.663522720336914 | latent_loss: 33.32207489013672 | total_loss: 19.9927978515625\n",
      "Epoch: 341 | recon_loss: 6.675406455993652 | latent_loss: 33.06376266479492 | total_loss: 19.869585037231445\n",
      "Epoch: 342 | recon_loss: 6.718456268310547 | latent_loss: 33.60372543334961 | total_loss: 20.161090850830078\n",
      "Epoch: 343 | recon_loss: 6.776450157165527 | latent_loss: 32.72224426269531 | total_loss: 19.749347686767578\n",
      "Epoch: 344 | recon_loss: 6.792552947998047 | latent_loss: 33.10365676879883 | total_loss: 19.948104858398438\n",
      "Epoch: 345 | recon_loss: 6.7598748207092285 | latent_loss: 33.00521469116211 | total_loss: 19.882545471191406\n",
      "Epoch: 346 | recon_loss: 6.751561164855957 | latent_loss: 32.903076171875 | total_loss: 19.82731819152832\n",
      "Epoch: 347 | recon_loss: 6.725270748138428 | latent_loss: 33.12109375 | total_loss: 19.923181533813477\n",
      "Epoch: 348 | recon_loss: 6.769923210144043 | latent_loss: 35.92329406738281 | total_loss: 21.346609115600586\n",
      "Epoch: 349 | recon_loss: 6.739409446716309 | latent_loss: 36.75666046142578 | total_loss: 21.748035430908203\n",
      "Epoch: 350 | recon_loss: 6.661542892456055 | latent_loss: 36.13066101074219 | total_loss: 21.396102905273438\n",
      "Epoch: 351 | recon_loss: 6.572272300720215 | latent_loss: 35.73753356933594 | total_loss: 21.154903411865234\n",
      "Epoch: 352 | recon_loss: 6.499215126037598 | latent_loss: 35.64209747314453 | total_loss: 21.070655822753906\n",
      "Epoch: 353 | recon_loss: 6.448489189147949 | latent_loss: 34.65774154663086 | total_loss: 20.553115844726562\n",
      "Epoch: 354 | recon_loss: 6.362871170043945 | latent_loss: 34.64278793334961 | total_loss: 20.502830505371094\n",
      "Epoch: 355 | recon_loss: 6.334672451019287 | latent_loss: 34.683502197265625 | total_loss: 20.50908660888672\n",
      "Epoch: 356 | recon_loss: 6.167238235473633 | latent_loss: 34.03504180908203 | total_loss: 20.101139068603516\n",
      "Epoch: 357 | recon_loss: 6.140580654144287 | latent_loss: 34.27979278564453 | total_loss: 20.210186004638672\n",
      "Epoch: 358 | recon_loss: 6.110332489013672 | latent_loss: 34.27403259277344 | total_loss: 20.192182540893555\n",
      "Epoch: 359 | recon_loss: 6.106585502624512 | latent_loss: 33.898929595947266 | total_loss: 20.002758026123047\n",
      "Epoch: 360 | recon_loss: 6.138886451721191 | latent_loss: 33.79835891723633 | total_loss: 19.9686222076416\n",
      "Epoch: 361 | recon_loss: 6.145097732543945 | latent_loss: 33.67853927612305 | total_loss: 19.911819458007812\n",
      "Epoch: 362 | recon_loss: 6.221004009246826 | latent_loss: 33.53034973144531 | total_loss: 19.87567710876465\n",
      "Epoch: 363 | recon_loss: 6.294892311096191 | latent_loss: 33.50090789794922 | total_loss: 19.897899627685547\n",
      "Epoch: 364 | recon_loss: 6.372432708740234 | latent_loss: 33.063167572021484 | total_loss: 19.71780014038086\n",
      "Epoch: 365 | recon_loss: 6.325811862945557 | latent_loss: 32.92885208129883 | total_loss: 19.62733268737793\n",
      "Epoch: 366 | recon_loss: 6.257054328918457 | latent_loss: 32.81832504272461 | total_loss: 19.537689208984375\n",
      "Epoch: 367 | recon_loss: 6.243853569030762 | latent_loss: 32.74552917480469 | total_loss: 19.494691848754883\n",
      "Epoch: 368 | recon_loss: 6.265293598175049 | latent_loss: 33.15438461303711 | total_loss: 19.7098388671875\n",
      "Epoch: 369 | recon_loss: 6.257384300231934 | latent_loss: 33.131343841552734 | total_loss: 19.694364547729492\n",
      "Epoch: 370 | recon_loss: 6.2615461349487305 | latent_loss: 33.26722717285156 | total_loss: 19.764387130737305\n",
      "Epoch: 371 | recon_loss: 6.26870584487915 | latent_loss: 32.77435302734375 | total_loss: 19.521530151367188\n",
      "Epoch: 372 | recon_loss: 6.268733024597168 | latent_loss: 32.737403869628906 | total_loss: 19.503068923950195\n",
      "Epoch: 373 | recon_loss: 6.251300811767578 | latent_loss: 33.09614562988281 | total_loss: 19.673723220825195\n",
      "Epoch: 374 | recon_loss: 6.238609790802002 | latent_loss: 32.5640869140625 | total_loss: 19.401348114013672\n",
      "Epoch: 375 | recon_loss: 6.2399420738220215 | latent_loss: 32.688499450683594 | total_loss: 19.46422004699707\n",
      "Epoch: 376 | recon_loss: 6.241417407989502 | latent_loss: 32.44936752319336 | total_loss: 19.34539222717285\n",
      "Epoch: 377 | recon_loss: 6.240874290466309 | latent_loss: 31.997941970825195 | total_loss: 19.119407653808594\n",
      "Epoch: 378 | recon_loss: 6.262521743774414 | latent_loss: 32.61092758178711 | total_loss: 19.436725616455078\n",
      "Epoch: 379 | recon_loss: 6.273317337036133 | latent_loss: 32.33137512207031 | total_loss: 19.302345275878906\n",
      "Epoch: 380 | recon_loss: 6.2634477615356445 | latent_loss: 32.338829040527344 | total_loss: 19.301137924194336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 381 | recon_loss: 6.2477803230285645 | latent_loss: 32.3408203125 | total_loss: 19.294300079345703\n",
      "Epoch: 382 | recon_loss: 6.2444000244140625 | latent_loss: 32.42905807495117 | total_loss: 19.336729049682617\n",
      "Epoch: 383 | recon_loss: 6.249022483825684 | latent_loss: 32.05897521972656 | total_loss: 19.15399932861328\n",
      "Epoch: 384 | recon_loss: 6.241152763366699 | latent_loss: 32.07624435424805 | total_loss: 19.15869903564453\n",
      "Epoch: 385 | recon_loss: 6.2487568855285645 | latent_loss: 32.31605529785156 | total_loss: 19.282405853271484\n",
      "Epoch: 386 | recon_loss: 6.245834827423096 | latent_loss: 32.17145538330078 | total_loss: 19.20864486694336\n",
      "Epoch: 387 | recon_loss: 6.246640205383301 | latent_loss: 32.03481674194336 | total_loss: 19.140727996826172\n",
      "Epoch: 388 | recon_loss: 6.238192558288574 | latent_loss: 32.00019073486328 | total_loss: 19.119192123413086\n",
      "Epoch: 389 | recon_loss: 6.202432632446289 | latent_loss: 31.90260887145996 | total_loss: 19.052520751953125\n",
      "Epoch: 390 | recon_loss: 6.17466402053833 | latent_loss: 32.05979919433594 | total_loss: 19.117231369018555\n",
      "Epoch: 391 | recon_loss: 6.241716384887695 | latent_loss: 31.949562072753906 | total_loss: 19.095638275146484\n",
      "Epoch: 392 | recon_loss: 6.327862739562988 | latent_loss: 31.83426856994629 | total_loss: 19.081066131591797\n",
      "Epoch: 393 | recon_loss: 6.315585136413574 | latent_loss: 32.1141471862793 | total_loss: 19.214866638183594\n",
      "Epoch: 394 | recon_loss: 6.294582843780518 | latent_loss: 31.956825256347656 | total_loss: 19.125703811645508\n",
      "Epoch: 395 | recon_loss: 6.2626051902771 | latent_loss: 31.835880279541016 | total_loss: 19.04924201965332\n",
      "Epoch: 396 | recon_loss: 6.23405122756958 | latent_loss: 32.1641845703125 | total_loss: 19.19911766052246\n",
      "Epoch: 397 | recon_loss: 6.232990264892578 | latent_loss: 31.66288185119629 | total_loss: 18.94793701171875\n",
      "Epoch: 398 | recon_loss: 6.212778091430664 | latent_loss: 32.07135772705078 | total_loss: 19.142066955566406\n",
      "Epoch: 399 | recon_loss: 6.180996417999268 | latent_loss: 31.76497459411621 | total_loss: 18.972986221313477\n",
      "Epoch: 400 | recon_loss: 6.1797590255737305 | latent_loss: 31.67970848083496 | total_loss: 18.929733276367188\n",
      "Epoch: 401 | recon_loss: 6.188066005706787 | latent_loss: 31.891305923461914 | total_loss: 19.03968620300293\n",
      "Epoch: 402 | recon_loss: 6.216132164001465 | latent_loss: 31.787078857421875 | total_loss: 19.001605987548828\n",
      "Epoch: 403 | recon_loss: 6.237401962280273 | latent_loss: 31.66250991821289 | total_loss: 18.949954986572266\n",
      "Epoch: 404 | recon_loss: 6.235474109649658 | latent_loss: 31.85708236694336 | total_loss: 19.04627799987793\n",
      "Epoch: 405 | recon_loss: 6.227677822113037 | latent_loss: 31.683162689208984 | total_loss: 18.955419540405273\n",
      "Epoch: 406 | recon_loss: 6.247643947601318 | latent_loss: 31.54887580871582 | total_loss: 18.89826011657715\n",
      "Epoch: 407 | recon_loss: 6.249096393585205 | latent_loss: 31.533233642578125 | total_loss: 18.891164779663086\n",
      "Epoch: 408 | recon_loss: 6.248590469360352 | latent_loss: 31.214548110961914 | total_loss: 18.731569290161133\n",
      "Epoch: 409 | recon_loss: 6.224703311920166 | latent_loss: 31.71234130859375 | total_loss: 18.968523025512695\n",
      "Epoch: 410 | recon_loss: 6.23868465423584 | latent_loss: 31.466583251953125 | total_loss: 18.85263442993164\n",
      "Epoch: 411 | recon_loss: 6.233641624450684 | latent_loss: 31.576847076416016 | total_loss: 18.905244827270508\n",
      "Epoch: 412 | recon_loss: 6.225093841552734 | latent_loss: 31.46908950805664 | total_loss: 18.847091674804688\n",
      "Epoch: 413 | recon_loss: 6.217226028442383 | latent_loss: 31.416311264038086 | total_loss: 18.816768646240234\n",
      "Epoch: 414 | recon_loss: 6.2228264808654785 | latent_loss: 31.61698341369629 | total_loss: 18.919904708862305\n",
      "Epoch: 415 | recon_loss: 6.2319841384887695 | latent_loss: 31.35563087463379 | total_loss: 18.793807983398438\n",
      "Epoch: 416 | recon_loss: 6.229975700378418 | latent_loss: 31.680185317993164 | total_loss: 18.955080032348633\n",
      "Epoch: 417 | recon_loss: 6.219582557678223 | latent_loss: 31.544809341430664 | total_loss: 18.8821964263916\n",
      "Epoch: 418 | recon_loss: 6.218227386474609 | latent_loss: 31.44159698486328 | total_loss: 18.829912185668945\n",
      "Epoch: 419 | recon_loss: 6.244311332702637 | latent_loss: 31.16143035888672 | total_loss: 18.702871322631836\n",
      "Epoch: 420 | recon_loss: 6.291347503662109 | latent_loss: 31.39589500427246 | total_loss: 18.84362030029297\n",
      "Epoch: 421 | recon_loss: 6.283050060272217 | latent_loss: 31.534664154052734 | total_loss: 18.908857345581055\n",
      "Epoch: 422 | recon_loss: 6.2420244216918945 | latent_loss: 31.352291107177734 | total_loss: 18.797157287597656\n",
      "Epoch: 423 | recon_loss: 6.196587085723877 | latent_loss: 31.627153396606445 | total_loss: 18.9118709564209\n",
      "Epoch: 424 | recon_loss: 6.191615581512451 | latent_loss: 31.30242156982422 | total_loss: 18.747018814086914\n",
      "Epoch: 425 | recon_loss: 6.179773807525635 | latent_loss: 31.426523208618164 | total_loss: 18.80314826965332\n",
      "Epoch: 426 | recon_loss: 6.202792644500732 | latent_loss: 31.621721267700195 | total_loss: 18.912256240844727\n",
      "Epoch: 427 | recon_loss: 6.260912895202637 | latent_loss: 31.357147216796875 | total_loss: 18.809030532836914\n",
      "Epoch: 428 | recon_loss: 6.240121364593506 | latent_loss: 31.162424087524414 | total_loss: 18.70127296447754\n",
      "Epoch: 429 | recon_loss: 6.211930274963379 | latent_loss: 31.12278175354004 | total_loss: 18.667356491088867\n",
      "Epoch: 430 | recon_loss: 6.140341758728027 | latent_loss: 31.261695861816406 | total_loss: 18.701019287109375\n",
      "Epoch: 431 | recon_loss: 6.123478889465332 | latent_loss: 31.38153076171875 | total_loss: 18.752504348754883\n",
      "Epoch: 432 | recon_loss: 6.126642227172852 | latent_loss: 31.34136962890625 | total_loss: 18.734004974365234\n",
      "Epoch: 433 | recon_loss: 6.13319206237793 | latent_loss: 30.977317810058594 | total_loss: 18.555255889892578\n",
      "Epoch: 434 | recon_loss: 6.1383819580078125 | latent_loss: 31.18293571472168 | total_loss: 18.660659790039062\n",
      "Epoch: 435 | recon_loss: 6.13761043548584 | latent_loss: 31.21202278137207 | total_loss: 18.674816131591797\n",
      "Epoch: 436 | recon_loss: 6.128201961517334 | latent_loss: 31.383174896240234 | total_loss: 18.755687713623047\n",
      "Epoch: 437 | recon_loss: 6.134039878845215 | latent_loss: 31.07275390625 | total_loss: 18.603397369384766\n",
      "Epoch: 438 | recon_loss: 6.132493019104004 | latent_loss: 31.349464416503906 | total_loss: 18.740978240966797\n",
      "Epoch: 439 | recon_loss: 6.133020877838135 | latent_loss: 31.12525749206543 | total_loss: 18.629138946533203\n",
      "Epoch: 440 | recon_loss: 6.133300304412842 | latent_loss: 31.08078956604004 | total_loss: 18.607044219970703\n",
      "Epoch: 441 | recon_loss: 6.135166168212891 | latent_loss: 30.959035873413086 | total_loss: 18.547100067138672\n",
      "Epoch: 442 | recon_loss: 6.13093376159668 | latent_loss: 31.04537010192871 | total_loss: 18.588151931762695\n",
      "Epoch: 443 | recon_loss: 6.127308368682861 | latent_loss: 31.082651138305664 | total_loss: 18.60498046875\n",
      "Epoch: 444 | recon_loss: 6.120179176330566 | latent_loss: 31.17708396911621 | total_loss: 18.648632049560547\n",
      "Epoch: 445 | recon_loss: 6.121521949768066 | latent_loss: 31.129390716552734 | total_loss: 18.625455856323242\n",
      "Epoch: 446 | recon_loss: 6.130098342895508 | latent_loss: 31.147287368774414 | total_loss: 18.63869285583496\n",
      "Epoch: 447 | recon_loss: 6.136727809906006 | latent_loss: 30.70589828491211 | total_loss: 18.42131233215332\n",
      "Epoch: 448 | recon_loss: 6.130837440490723 | latent_loss: 30.99980354309082 | total_loss: 18.56532096862793\n",
      "Epoch: 449 | recon_loss: 6.136797904968262 | latent_loss: 31.023759841918945 | total_loss: 18.580278396606445\n",
      "Epoch: 450 | recon_loss: 6.143924236297607 | latent_loss: 30.91674041748047 | total_loss: 18.530332565307617\n",
      "Epoch: 451 | recon_loss: 6.135408401489258 | latent_loss: 30.73297882080078 | total_loss: 18.434192657470703\n",
      "Epoch: 452 | recon_loss: 6.1316423416137695 | latent_loss: 31.074235916137695 | total_loss: 18.60293960571289\n",
      "Epoch: 453 | recon_loss: 6.123375415802002 | latent_loss: 30.79102897644043 | total_loss: 18.457202911376953\n",
      "Epoch: 454 | recon_loss: 6.119296550750732 | latent_loss: 30.87059783935547 | total_loss: 18.49494743347168\n",
      "Epoch: 455 | recon_loss: 6.128006935119629 | latent_loss: 30.83717918395996 | total_loss: 18.482593536376953\n",
      "Epoch: 456 | recon_loss: 6.132615089416504 | latent_loss: 30.83690643310547 | total_loss: 18.484760284423828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 457 | recon_loss: 6.122962951660156 | latent_loss: 30.825408935546875 | total_loss: 18.474185943603516\n",
      "Epoch: 458 | recon_loss: 6.128769397735596 | latent_loss: 30.805702209472656 | total_loss: 18.467235565185547\n",
      "Epoch: 459 | recon_loss: 6.1303510665893555 | latent_loss: 30.905216217041016 | total_loss: 18.517784118652344\n",
      "Epoch: 460 | recon_loss: 6.125449180603027 | latent_loss: 30.60649299621582 | total_loss: 18.365970611572266\n",
      "Epoch: 461 | recon_loss: 6.121362686157227 | latent_loss: 30.748159408569336 | total_loss: 18.43476104736328\n",
      "Epoch: 462 | recon_loss: 6.120688438415527 | latent_loss: 30.55179214477539 | total_loss: 18.336240768432617\n",
      "Epoch: 463 | recon_loss: 6.117104530334473 | latent_loss: 30.65513038635254 | total_loss: 18.386117935180664\n",
      "Epoch: 464 | recon_loss: 6.124664306640625 | latent_loss: 30.95820426940918 | total_loss: 18.54143524169922\n",
      "Epoch: 465 | recon_loss: 6.1218438148498535 | latent_loss: 30.646127700805664 | total_loss: 18.38398551940918\n",
      "Epoch: 466 | recon_loss: 6.1149091720581055 | latent_loss: 30.818044662475586 | total_loss: 18.466476440429688\n",
      "Epoch: 467 | recon_loss: 6.137962341308594 | latent_loss: 30.77942657470703 | total_loss: 18.458694458007812\n",
      "Epoch: 468 | recon_loss: 6.113796234130859 | latent_loss: 30.936025619506836 | total_loss: 18.52490997314453\n",
      "Epoch: 469 | recon_loss: 6.070866107940674 | latent_loss: 30.976722717285156 | total_loss: 18.523794174194336\n",
      "Epoch: 470 | recon_loss: 6.0216217041015625 | latent_loss: 30.92794418334961 | total_loss: 18.474782943725586\n",
      "Epoch: 471 | recon_loss: 5.991809368133545 | latent_loss: 31.11257553100586 | total_loss: 18.55219268798828\n",
      "Epoch: 472 | recon_loss: 5.915082931518555 | latent_loss: 31.18274688720703 | total_loss: 18.54891586303711\n",
      "Epoch: 473 | recon_loss: 5.908114433288574 | latent_loss: 31.556535720825195 | total_loss: 18.732324600219727\n",
      "Epoch: 474 | recon_loss: 6.193927764892578 | latent_loss: 31.027700424194336 | total_loss: 18.61081314086914\n",
      "Epoch: 475 | recon_loss: 6.341706275939941 | latent_loss: 30.607669830322266 | total_loss: 18.474687576293945\n",
      "Epoch: 476 | recon_loss: 6.388921737670898 | latent_loss: 30.492265701293945 | total_loss: 18.440593719482422\n",
      "Epoch: 477 | recon_loss: 6.309814929962158 | latent_loss: 30.45499038696289 | total_loss: 18.382402420043945\n",
      "Epoch: 478 | recon_loss: 6.211087703704834 | latent_loss: 30.463478088378906 | total_loss: 18.337282180786133\n",
      "Epoch: 479 | recon_loss: 6.2945780754089355 | latent_loss: 30.35413932800293 | total_loss: 18.324357986450195\n",
      "Epoch: 480 | recon_loss: 6.352408409118652 | latent_loss: 30.79378318786621 | total_loss: 18.573095321655273\n",
      "Epoch: 481 | recon_loss: 6.306193828582764 | latent_loss: 30.787296295166016 | total_loss: 18.54674530029297\n",
      "Epoch: 482 | recon_loss: 6.203725814819336 | latent_loss: 30.491756439208984 | total_loss: 18.347740173339844\n",
      "Epoch: 483 | recon_loss: 6.18657112121582 | latent_loss: 30.56199836730957 | total_loss: 18.374284744262695\n",
      "Epoch: 484 | recon_loss: 6.169349670410156 | latent_loss: 30.500802993774414 | total_loss: 18.33507537841797\n",
      "Epoch: 485 | recon_loss: 6.148510932922363 | latent_loss: 30.62657356262207 | total_loss: 18.387542724609375\n",
      "Epoch: 486 | recon_loss: 6.151999473571777 | latent_loss: 30.42379379272461 | total_loss: 18.28789710998535\n",
      "Epoch: 487 | recon_loss: 6.1453471183776855 | latent_loss: 30.676300048828125 | total_loss: 18.410823822021484\n",
      "Epoch: 488 | recon_loss: 6.173126220703125 | latent_loss: 30.55950927734375 | total_loss: 18.366317749023438\n",
      "Epoch: 489 | recon_loss: 6.231216907501221 | latent_loss: 30.47549057006836 | total_loss: 18.35335350036621\n",
      "Epoch: 490 | recon_loss: 6.2293500900268555 | latent_loss: 30.48032569885254 | total_loss: 18.35483741760254\n",
      "Epoch: 491 | recon_loss: 6.199233531951904 | latent_loss: 30.191158294677734 | total_loss: 18.1951961517334\n",
      "Epoch: 492 | recon_loss: 6.226059913635254 | latent_loss: 30.41117286682129 | total_loss: 18.31861686706543\n",
      "Epoch: 493 | recon_loss: 6.226866245269775 | latent_loss: 30.21428680419922 | total_loss: 18.220577239990234\n",
      "Epoch: 494 | recon_loss: 6.17647647857666 | latent_loss: 30.35081672668457 | total_loss: 18.263647079467773\n",
      "Epoch: 495 | recon_loss: 6.147220611572266 | latent_loss: 30.33730125427246 | total_loss: 18.242259979248047\n",
      "Epoch: 496 | recon_loss: 6.664690971374512 | latent_loss: 32.87017059326172 | total_loss: 19.767431259155273\n",
      "Epoch: 497 | recon_loss: 6.564216136932373 | latent_loss: 36.597442626953125 | total_loss: 21.580829620361328\n",
      "Epoch: 498 | recon_loss: 6.75050687789917 | latent_loss: 37.05924606323242 | total_loss: 21.904876708984375\n",
      "Epoch: 499 | recon_loss: 6.762789249420166 | latent_loss: 32.53641128540039 | total_loss: 19.649600982666016\n",
      "Epoch: 500 | recon_loss: 6.642718315124512 | latent_loss: 32.325931549072266 | total_loss: 19.484325408935547\n",
      "Epoch: 501 | recon_loss: 6.688388824462891 | latent_loss: 31.858219146728516 | total_loss: 19.273303985595703\n",
      "Epoch: 502 | recon_loss: 6.617085933685303 | latent_loss: 31.44379997253418 | total_loss: 19.03044319152832\n",
      "Epoch: 503 | recon_loss: 6.68259334564209 | latent_loss: 31.658700942993164 | total_loss: 19.17064666748047\n",
      "Epoch: 504 | recon_loss: 6.868780136108398 | latent_loss: 30.850341796875 | total_loss: 18.859561920166016\n",
      "Epoch: 505 | recon_loss: 6.867530345916748 | latent_loss: 31.204498291015625 | total_loss: 19.036014556884766\n",
      "Epoch: 506 | recon_loss: 6.975067615509033 | latent_loss: 30.938358306884766 | total_loss: 18.95671272277832\n",
      "Epoch: 507 | recon_loss: 7.130849361419678 | latent_loss: 32.06826400756836 | total_loss: 19.59955596923828\n",
      "Epoch: 508 | recon_loss: 6.758429050445557 | latent_loss: 34.4648323059082 | total_loss: 20.611631393432617\n",
      "Epoch: 509 | recon_loss: 6.685397148132324 | latent_loss: 32.694400787353516 | total_loss: 19.689899444580078\n",
      "Epoch: 510 | recon_loss: 6.812559127807617 | latent_loss: 31.734994888305664 | total_loss: 19.27377700805664\n",
      "Epoch: 511 | recon_loss: 6.951138973236084 | latent_loss: 30.99062728881836 | total_loss: 18.970882415771484\n",
      "Epoch: 512 | recon_loss: 7.085694789886475 | latent_loss: 31.11334991455078 | total_loss: 19.09952163696289\n",
      "Epoch: 513 | recon_loss: 7.0422468185424805 | latent_loss: 31.103878021240234 | total_loss: 19.073062896728516\n",
      "Epoch: 514 | recon_loss: 6.046781539916992 | latent_loss: 37.21873474121094 | total_loss: 21.63275909423828\n",
      "Epoch: 515 | recon_loss: 6.0320234298706055 | latent_loss: 35.9481086730957 | total_loss: 20.990066528320312\n",
      "Epoch: 516 | recon_loss: 6.346051216125488 | latent_loss: 33.269405364990234 | total_loss: 19.807727813720703\n",
      "Epoch: 517 | recon_loss: 6.667470455169678 | latent_loss: 32.15155029296875 | total_loss: 19.409509658813477\n",
      "Epoch: 518 | recon_loss: 6.6175689697265625 | latent_loss: 31.533103942871094 | total_loss: 19.075336456298828\n",
      "Epoch: 519 | recon_loss: 6.536072731018066 | latent_loss: 31.15933609008789 | total_loss: 18.84770393371582\n",
      "Epoch: 520 | recon_loss: 6.4698333740234375 | latent_loss: 30.733102798461914 | total_loss: 18.60146713256836\n",
      "Epoch: 521 | recon_loss: 6.465229034423828 | latent_loss: 30.66811180114746 | total_loss: 18.566669464111328\n",
      "Epoch: 522 | recon_loss: 6.444277286529541 | latent_loss: 30.68931007385254 | total_loss: 18.56679344177246\n",
      "Epoch: 523 | recon_loss: 6.454201698303223 | latent_loss: 30.69924545288086 | total_loss: 18.576723098754883\n",
      "Epoch: 524 | recon_loss: 6.423907279968262 | latent_loss: 31.08963394165039 | total_loss: 18.756771087646484\n",
      "Epoch: 525 | recon_loss: 6.332749366760254 | latent_loss: 31.67055892944336 | total_loss: 19.00165367126465\n",
      "Epoch: 526 | recon_loss: 6.272905349731445 | latent_loss: 31.742820739746094 | total_loss: 19.007862091064453\n",
      "Epoch: 527 | recon_loss: 6.887855529785156 | latent_loss: 35.17389678955078 | total_loss: 21.03087615966797\n",
      "Epoch: 528 | recon_loss: 7.16596794128418 | latent_loss: 36.8752555847168 | total_loss: 22.020610809326172\n",
      "Epoch: 529 | recon_loss: 6.637821674346924 | latent_loss: 33.82427215576172 | total_loss: 20.231046676635742\n",
      "Epoch: 530 | recon_loss: 6.427667617797852 | latent_loss: 34.09181594848633 | total_loss: 20.259742736816406\n",
      "Epoch: 531 | recon_loss: 6.298860549926758 | latent_loss: 33.894805908203125 | total_loss: 20.096832275390625\n",
      "Epoch: 532 | recon_loss: 6.364563941955566 | latent_loss: 33.36796188354492 | total_loss: 19.866262435913086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 533 | recon_loss: 6.4324140548706055 | latent_loss: 32.82350540161133 | total_loss: 19.627960205078125\n",
      "Epoch: 534 | recon_loss: 6.415338516235352 | latent_loss: 32.14445114135742 | total_loss: 19.279895782470703\n",
      "Epoch: 535 | recon_loss: 6.4316301345825195 | latent_loss: 31.884870529174805 | total_loss: 19.15825080871582\n",
      "Epoch: 536 | recon_loss: 6.412074089050293 | latent_loss: 31.817420959472656 | total_loss: 19.114748001098633\n",
      "Epoch: 537 | recon_loss: 6.473259925842285 | latent_loss: 31.267921447753906 | total_loss: 18.870590209960938\n",
      "Epoch: 538 | recon_loss: 6.496920108795166 | latent_loss: 31.25899314880371 | total_loss: 18.87795639038086\n",
      "Epoch: 539 | recon_loss: 6.584000587463379 | latent_loss: 31.20808982849121 | total_loss: 18.896045684814453\n",
      "Epoch: 540 | recon_loss: 6.6292853355407715 | latent_loss: 30.841535568237305 | total_loss: 18.735410690307617\n",
      "Epoch: 541 | recon_loss: 6.77878475189209 | latent_loss: 30.83452033996582 | total_loss: 18.806652069091797\n",
      "Epoch: 542 | recon_loss: 6.734975814819336 | latent_loss: 30.819637298583984 | total_loss: 18.777305603027344\n",
      "Epoch: 543 | recon_loss: 6.08696174621582 | latent_loss: 33.11490249633789 | total_loss: 19.600933074951172\n",
      "Epoch: 544 | recon_loss: 5.6841511726379395 | latent_loss: 67.9751968383789 | total_loss: 36.829673767089844\n",
      "Epoch: 545 | recon_loss: 5.720008850097656 | latent_loss: 57.94987106323242 | total_loss: 31.83493995666504\n",
      "Epoch: 546 | recon_loss: 6.074872016906738 | latent_loss: 45.535762786865234 | total_loss: 25.805316925048828\n",
      "Epoch: 547 | recon_loss: 6.228116035461426 | latent_loss: 43.86394119262695 | total_loss: 25.04602813720703\n",
      "Epoch: 548 | recon_loss: 6.289107322692871 | latent_loss: 41.62600326538086 | total_loss: 23.957555770874023\n",
      "Epoch: 549 | recon_loss: 6.2742815017700195 | latent_loss: 40.21476364135742 | total_loss: 23.244522094726562\n",
      "Epoch: 550 | recon_loss: 6.274944305419922 | latent_loss: 37.840721130371094 | total_loss: 22.057832717895508\n",
      "Epoch: 551 | recon_loss: 6.454959869384766 | latent_loss: 37.25263977050781 | total_loss: 21.85379981994629\n",
      "Epoch: 552 | recon_loss: 6.522123336791992 | latent_loss: 36.45789337158203 | total_loss: 21.490009307861328\n",
      "Epoch: 553 | recon_loss: 6.534964561462402 | latent_loss: 36.02669906616211 | total_loss: 21.280832290649414\n",
      "Epoch: 554 | recon_loss: 6.590095520019531 | latent_loss: 36.07080841064453 | total_loss: 21.33045196533203\n",
      "Epoch: 555 | recon_loss: 6.661111831665039 | latent_loss: 35.22981262207031 | total_loss: 20.94546127319336\n",
      "Epoch: 556 | recon_loss: 6.761417388916016 | latent_loss: 34.847049713134766 | total_loss: 20.80423355102539\n",
      "Epoch: 557 | recon_loss: 6.760188102722168 | latent_loss: 34.239479064941406 | total_loss: 20.499834060668945\n",
      "Epoch: 558 | recon_loss: 6.773006439208984 | latent_loss: 33.61590576171875 | total_loss: 20.194456100463867\n",
      "Epoch: 559 | recon_loss: 6.7248311042785645 | latent_loss: 33.31828308105469 | total_loss: 20.021556854248047\n",
      "Epoch: 560 | recon_loss: 6.755769729614258 | latent_loss: 33.64186096191406 | total_loss: 20.198814392089844\n",
      "Epoch: 561 | recon_loss: 6.790656089782715 | latent_loss: 33.08226013183594 | total_loss: 19.936458587646484\n",
      "Epoch: 562 | recon_loss: 6.781092643737793 | latent_loss: 33.33799743652344 | total_loss: 20.059545516967773\n",
      "Epoch: 563 | recon_loss: 6.837026596069336 | latent_loss: 32.92390823364258 | total_loss: 19.88046646118164\n",
      "Epoch: 564 | recon_loss: 6.889978885650635 | latent_loss: 32.78126525878906 | total_loss: 19.835622787475586\n",
      "Epoch: 565 | recon_loss: 6.937564849853516 | latent_loss: 33.16381072998047 | total_loss: 20.050687789916992\n",
      "Epoch: 566 | recon_loss: 6.932748794555664 | latent_loss: 32.104644775390625 | total_loss: 19.518695831298828\n",
      "Epoch: 567 | recon_loss: 6.883390426635742 | latent_loss: 32.096168518066406 | total_loss: 19.48978042602539\n",
      "Epoch: 568 | recon_loss: 6.835227012634277 | latent_loss: 32.16764450073242 | total_loss: 19.501436233520508\n",
      "Epoch: 569 | recon_loss: 6.813511848449707 | latent_loss: 32.10546875 | total_loss: 19.459489822387695\n",
      "Epoch: 570 | recon_loss: 6.702801704406738 | latent_loss: 32.266929626464844 | total_loss: 19.484865188598633\n",
      "Epoch: 571 | recon_loss: 6.602889060974121 | latent_loss: 31.624794006347656 | total_loss: 19.113842010498047\n",
      "Epoch: 572 | recon_loss: 6.602006435394287 | latent_loss: 31.971139907836914 | total_loss: 19.28657341003418\n",
      "Epoch: 573 | recon_loss: 6.540886878967285 | latent_loss: 31.683420181274414 | total_loss: 19.112154006958008\n",
      "Epoch: 574 | recon_loss: 6.560779571533203 | latent_loss: 31.832353591918945 | total_loss: 19.19656753540039\n",
      "Epoch: 575 | recon_loss: 6.596163272857666 | latent_loss: 31.256338119506836 | total_loss: 18.926250457763672\n",
      "Epoch: 576 | recon_loss: 6.663260459899902 | latent_loss: 31.55953598022461 | total_loss: 19.111398696899414\n",
      "Epoch: 577 | recon_loss: 6.662874221801758 | latent_loss: 31.59998893737793 | total_loss: 19.131431579589844\n",
      "Epoch: 578 | recon_loss: 6.6623640060424805 | latent_loss: 30.830169677734375 | total_loss: 18.746267318725586\n",
      "Epoch: 579 | recon_loss: 6.652482032775879 | latent_loss: 31.2659912109375 | total_loss: 18.95923614501953\n",
      "Epoch: 580 | recon_loss: 6.659453868865967 | latent_loss: 31.04009246826172 | total_loss: 18.849773406982422\n",
      "Epoch: 581 | recon_loss: 6.637441635131836 | latent_loss: 31.14781379699707 | total_loss: 18.892627716064453\n",
      "Epoch: 582 | recon_loss: 6.578021049499512 | latent_loss: 30.97220802307129 | total_loss: 18.775114059448242\n",
      "Epoch: 583 | recon_loss: 6.641469955444336 | latent_loss: 30.97267723083496 | total_loss: 18.80707359313965\n",
      "Epoch: 584 | recon_loss: 6.688596725463867 | latent_loss: 31.102874755859375 | total_loss: 18.895736694335938\n",
      "Epoch: 585 | recon_loss: 6.976893901824951 | latent_loss: 32.30582809448242 | total_loss: 19.641361236572266\n",
      "Epoch: 586 | recon_loss: 6.734631061553955 | latent_loss: 32.6524658203125 | total_loss: 19.69354820251465\n",
      "Epoch: 587 | recon_loss: 6.593982696533203 | latent_loss: 32.97323989868164 | total_loss: 19.783611297607422\n",
      "Epoch: 588 | recon_loss: 6.84037446975708 | latent_loss: 33.23685073852539 | total_loss: 20.038612365722656\n",
      "Epoch: 589 | recon_loss: 6.91196346282959 | latent_loss: 32.09159469604492 | total_loss: 19.501779556274414\n",
      "Epoch: 590 | recon_loss: 7.069748878479004 | latent_loss: 31.730464935302734 | total_loss: 19.40010643005371\n",
      "Epoch: 591 | recon_loss: 7.126673698425293 | latent_loss: 31.27733612060547 | total_loss: 19.20200538635254\n",
      "Epoch: 592 | recon_loss: 7.076385498046875 | latent_loss: 31.32795524597168 | total_loss: 19.202171325683594\n",
      "Epoch: 593 | recon_loss: 7.121164321899414 | latent_loss: 31.14042854309082 | total_loss: 19.130796432495117\n",
      "Epoch: 594 | recon_loss: 7.134194374084473 | latent_loss: 30.88672637939453 | total_loss: 19.010459899902344\n",
      "Epoch: 595 | recon_loss: 7.056642532348633 | latent_loss: 30.745405197143555 | total_loss: 18.901023864746094\n",
      "Epoch: 596 | recon_loss: 7.003586769104004 | latent_loss: 31.02189064025879 | total_loss: 19.012739181518555\n",
      "Epoch: 597 | recon_loss: 6.911343574523926 | latent_loss: 31.038265228271484 | total_loss: 18.974803924560547\n",
      "Epoch: 598 | recon_loss: 6.843559741973877 | latent_loss: 30.37653923034668 | total_loss: 18.610050201416016\n",
      "Epoch: 599 | recon_loss: 6.87211799621582 | latent_loss: 30.50522232055664 | total_loss: 18.688671112060547\n",
      "Epoch: 600 | recon_loss: 6.404478073120117 | latent_loss: 54.527137756347656 | total_loss: 30.465808868408203\n",
      "Epoch: 601 | recon_loss: 6.277693748474121 | latent_loss: 63.01034164428711 | total_loss: 34.64401626586914\n",
      "Epoch: 602 | recon_loss: 6.578083038330078 | latent_loss: 43.47535705566406 | total_loss: 25.02672004699707\n",
      "Epoch: 603 | recon_loss: 6.97372579574585 | latent_loss: 36.80942916870117 | total_loss: 21.891576766967773\n",
      "Epoch: 604 | recon_loss: 7.361536979675293 | latent_loss: 33.37422180175781 | total_loss: 20.36787986755371\n",
      "Epoch: 605 | recon_loss: 7.4977874755859375 | latent_loss: 32.42394256591797 | total_loss: 19.960865020751953\n",
      "Epoch: 606 | recon_loss: 7.555282115936279 | latent_loss: 32.19857406616211 | total_loss: 19.876928329467773\n",
      "Epoch: 607 | recon_loss: 7.573314666748047 | latent_loss: 31.96810531616211 | total_loss: 19.770709991455078\n",
      "Epoch: 608 | recon_loss: 7.402609825134277 | latent_loss: 34.32191467285156 | total_loss: 20.862262725830078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 609 | recon_loss: 7.013854026794434 | latent_loss: 34.81000900268555 | total_loss: 20.91193199157715\n",
      "Epoch: 610 | recon_loss: 7.042571544647217 | latent_loss: 33.030677795410156 | total_loss: 20.036624908447266\n",
      "Epoch: 611 | recon_loss: 7.107721328735352 | latent_loss: 32.328285217285156 | total_loss: 19.718002319335938\n",
      "Epoch: 612 | recon_loss: 7.169374465942383 | latent_loss: 31.88576316833496 | total_loss: 19.527568817138672\n",
      "Epoch: 613 | recon_loss: 7.230658054351807 | latent_loss: 31.61614990234375 | total_loss: 19.423404693603516\n",
      "Epoch: 614 | recon_loss: 7.252181053161621 | latent_loss: 31.491533279418945 | total_loss: 19.371856689453125\n",
      "Epoch: 615 | recon_loss: 7.243815898895264 | latent_loss: 31.510786056518555 | total_loss: 19.377300262451172\n",
      "Epoch: 616 | recon_loss: 7.293452262878418 | latent_loss: 30.99969482421875 | total_loss: 19.146574020385742\n",
      "Epoch: 617 | recon_loss: 7.371057510375977 | latent_loss: 31.14186668395996 | total_loss: 19.25646209716797\n",
      "Epoch: 618 | recon_loss: 7.304600715637207 | latent_loss: 31.73349380493164 | total_loss: 19.519046783447266\n",
      "Epoch: 619 | recon_loss: 7.265459060668945 | latent_loss: 31.358619689941406 | total_loss: 19.31203842163086\n",
      "Epoch: 620 | recon_loss: 7.271467208862305 | latent_loss: 31.04217529296875 | total_loss: 19.156822204589844\n",
      "Epoch: 621 | recon_loss: 7.189183235168457 | latent_loss: 31.578887939453125 | total_loss: 19.384035110473633\n",
      "Epoch: 622 | recon_loss: 7.223851203918457 | latent_loss: 31.18864631652832 | total_loss: 19.206249237060547\n",
      "Epoch: 623 | recon_loss: 7.306977272033691 | latent_loss: 30.66809844970703 | total_loss: 18.987537384033203\n",
      "Epoch: 624 | recon_loss: 7.388951301574707 | latent_loss: 30.579872131347656 | total_loss: 18.984411239624023\n",
      "Epoch: 625 | recon_loss: 7.365874290466309 | latent_loss: 30.317779541015625 | total_loss: 18.841827392578125\n",
      "Epoch: 626 | recon_loss: 7.285951614379883 | latent_loss: 30.57535743713379 | total_loss: 18.930654525756836\n",
      "Epoch: 627 | recon_loss: 6.919608116149902 | latent_loss: 33.75358963012695 | total_loss: 20.336599349975586\n",
      "Epoch: 628 | recon_loss: 6.955588340759277 | latent_loss: 34.214969635009766 | total_loss: 20.58527946472168\n",
      "Epoch: 629 | recon_loss: 7.040303707122803 | latent_loss: 31.486995697021484 | total_loss: 19.263648986816406\n",
      "Epoch: 630 | recon_loss: 7.146139621734619 | latent_loss: 30.808128356933594 | total_loss: 18.977134704589844\n",
      "Epoch: 631 | recon_loss: 7.2777581214904785 | latent_loss: 30.70905876159668 | total_loss: 18.993408203125\n",
      "Epoch: 632 | recon_loss: 7.406381607055664 | latent_loss: 30.311147689819336 | total_loss: 18.8587646484375\n",
      "Epoch: 633 | recon_loss: 7.45196533203125 | latent_loss: 30.21303939819336 | total_loss: 18.832502365112305\n",
      "Epoch: 634 | recon_loss: 7.421324253082275 | latent_loss: 30.26742172241211 | total_loss: 18.84437370300293\n",
      "Epoch: 635 | recon_loss: 7.364805698394775 | latent_loss: 29.905738830566406 | total_loss: 18.635272979736328\n",
      "Epoch: 636 | recon_loss: 7.325162410736084 | latent_loss: 30.3284912109375 | total_loss: 18.826826095581055\n",
      "Epoch: 637 | recon_loss: 7.225975036621094 | latent_loss: 30.53203582763672 | total_loss: 18.879005432128906\n",
      "Epoch: 638 | recon_loss: 7.085043907165527 | latent_loss: 30.596275329589844 | total_loss: 18.840660095214844\n",
      "Epoch: 639 | recon_loss: 7.043359279632568 | latent_loss: 30.600746154785156 | total_loss: 18.822052001953125\n",
      "Epoch: 640 | recon_loss: 6.894608497619629 | latent_loss: 30.93515968322754 | total_loss: 18.914884567260742\n",
      "Epoch: 641 | recon_loss: 6.896403789520264 | latent_loss: 31.020681381225586 | total_loss: 18.958541870117188\n",
      "Epoch: 642 | recon_loss: 6.933030128479004 | latent_loss: 31.108333587646484 | total_loss: 19.020681381225586\n",
      "Epoch: 643 | recon_loss: 6.950750350952148 | latent_loss: 30.557716369628906 | total_loss: 18.754234313964844\n",
      "Epoch: 644 | recon_loss: 6.977745056152344 | latent_loss: 30.302085876464844 | total_loss: 18.639915466308594\n",
      "Epoch: 645 | recon_loss: 7.024445533752441 | latent_loss: 30.121381759643555 | total_loss: 18.572914123535156\n",
      "Epoch: 646 | recon_loss: 7.066590309143066 | latent_loss: 29.91150665283203 | total_loss: 18.48904800415039\n",
      "Epoch: 647 | recon_loss: 7.0848894119262695 | latent_loss: 30.093645095825195 | total_loss: 18.58926773071289\n",
      "Epoch: 648 | recon_loss: 6.983524799346924 | latent_loss: 29.9927978515625 | total_loss: 18.488161087036133\n",
      "Epoch: 649 | recon_loss: 6.754443168640137 | latent_loss: 30.586538314819336 | total_loss: 18.670490264892578\n",
      "Epoch: 650 | recon_loss: 6.520078182220459 | latent_loss: 31.208736419677734 | total_loss: 18.86440658569336\n",
      "Epoch: 651 | recon_loss: 6.49370002746582 | latent_loss: 31.2593994140625 | total_loss: 18.876548767089844\n",
      "Epoch: 652 | recon_loss: 6.468801975250244 | latent_loss: 30.706485748291016 | total_loss: 18.587644577026367\n",
      "Epoch: 653 | recon_loss: 6.559922218322754 | latent_loss: 30.56134033203125 | total_loss: 18.560630798339844\n",
      "Epoch: 654 | recon_loss: 6.683150768280029 | latent_loss: 30.42010498046875 | total_loss: 18.55162811279297\n",
      "Epoch: 655 | recon_loss: 6.755221366882324 | latent_loss: 30.633596420288086 | total_loss: 18.694408416748047\n",
      "Epoch: 656 | recon_loss: 6.881791114807129 | latent_loss: 33.01770782470703 | total_loss: 19.949748992919922\n",
      "Epoch: 657 | recon_loss: 6.640522003173828 | latent_loss: 33.63615417480469 | total_loss: 20.138338088989258\n",
      "Epoch: 658 | recon_loss: 6.631309509277344 | latent_loss: 34.11009979248047 | total_loss: 20.370704650878906\n",
      "Epoch: 659 | recon_loss: 6.686006546020508 | latent_loss: 32.23966979980469 | total_loss: 19.46283721923828\n",
      "Epoch: 660 | recon_loss: 6.734686374664307 | latent_loss: 31.90019416809082 | total_loss: 19.317440032958984\n",
      "Epoch: 661 | recon_loss: 6.821706771850586 | latent_loss: 31.333139419555664 | total_loss: 19.077423095703125\n",
      "Epoch: 662 | recon_loss: 6.963783264160156 | latent_loss: 31.12668228149414 | total_loss: 19.04523277282715\n",
      "Epoch: 663 | recon_loss: 6.985383033752441 | latent_loss: 30.67478370666504 | total_loss: 18.8300838470459\n",
      "Epoch: 664 | recon_loss: 6.960103988647461 | latent_loss: 30.412513732910156 | total_loss: 18.686309814453125\n",
      "Epoch: 665 | recon_loss: 6.942083835601807 | latent_loss: 30.02079963684082 | total_loss: 18.481441497802734\n",
      "Epoch: 666 | recon_loss: 6.93682336807251 | latent_loss: 30.026302337646484 | total_loss: 18.481563568115234\n",
      "Epoch: 667 | recon_loss: 7.125809669494629 | latent_loss: 30.17095184326172 | total_loss: 18.648380279541016\n",
      "Epoch: 668 | recon_loss: 7.845118522644043 | latent_loss: 33.61222457885742 | total_loss: 20.72867202758789\n",
      "Epoch: 669 | recon_loss: 7.947483062744141 | latent_loss: 35.02716064453125 | total_loss: 21.487321853637695\n",
      "Epoch: 670 | recon_loss: 8.158987045288086 | latent_loss: 34.21690368652344 | total_loss: 21.187946319580078\n",
      "Epoch: 671 | recon_loss: 8.106836318969727 | latent_loss: 32.881473541259766 | total_loss: 20.494155883789062\n",
      "Epoch: 672 | recon_loss: 8.280096054077148 | latent_loss: 32.87273406982422 | total_loss: 20.576416015625\n",
      "Epoch: 673 | recon_loss: 8.247060775756836 | latent_loss: 32.65168762207031 | total_loss: 20.44937515258789\n",
      "Epoch: 674 | recon_loss: 7.625646591186523 | latent_loss: 34.693153381347656 | total_loss: 21.159400939941406\n",
      "Epoch: 675 | recon_loss: 6.494933128356934 | latent_loss: 40.575836181640625 | total_loss: 23.535385131835938\n",
      "Epoch: 676 | recon_loss: 6.198257923126221 | latent_loss: 40.95241165161133 | total_loss: 23.575334548950195\n",
      "Epoch: 677 | recon_loss: 6.190098762512207 | latent_loss: 37.55372619628906 | total_loss: 21.871912002563477\n",
      "Epoch: 678 | recon_loss: 6.202817916870117 | latent_loss: 37.82946014404297 | total_loss: 22.01613998413086\n",
      "Epoch: 679 | recon_loss: 6.279956817626953 | latent_loss: 35.15315628051758 | total_loss: 20.716556549072266\n",
      "Epoch: 680 | recon_loss: 6.3525543212890625 | latent_loss: 34.25320053100586 | total_loss: 20.30287742614746\n",
      "Epoch: 681 | recon_loss: 6.590887069702148 | latent_loss: 33.39883041381836 | total_loss: 19.994857788085938\n",
      "Epoch: 682 | recon_loss: 6.73635196685791 | latent_loss: 32.65611267089844 | total_loss: 19.696231842041016\n",
      "Epoch: 683 | recon_loss: 6.825186252593994 | latent_loss: 32.77463150024414 | total_loss: 19.799909591674805\n",
      "Epoch: 684 | recon_loss: 6.9211883544921875 | latent_loss: 32.75540542602539 | total_loss: 19.83829689025879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 685 | recon_loss: 6.824094772338867 | latent_loss: 31.67546844482422 | total_loss: 19.24978256225586\n",
      "Epoch: 686 | recon_loss: 6.786660194396973 | latent_loss: 32.638607025146484 | total_loss: 19.71263313293457\n",
      "Epoch: 687 | recon_loss: 6.680420875549316 | latent_loss: 32.09082794189453 | total_loss: 19.385623931884766\n",
      "Epoch: 688 | recon_loss: 6.5002851486206055 | latent_loss: 31.53652572631836 | total_loss: 19.01840591430664\n",
      "Epoch: 689 | recon_loss: 6.42664909362793 | latent_loss: 31.83188819885254 | total_loss: 19.129268646240234\n",
      "Epoch: 690 | recon_loss: 6.4145002365112305 | latent_loss: 31.27639389038086 | total_loss: 18.845447540283203\n",
      "Epoch: 691 | recon_loss: 6.521292686462402 | latent_loss: 35.78058624267578 | total_loss: 21.15093994140625\n",
      "Epoch: 692 | recon_loss: 6.628165245056152 | latent_loss: 60.62466049194336 | total_loss: 33.62641143798828\n",
      "Epoch: 693 | recon_loss: 6.638492584228516 | latent_loss: 53.36806869506836 | total_loss: 30.003280639648438\n",
      "Epoch: 694 | recon_loss: 6.900334358215332 | latent_loss: 45.91325759887695 | total_loss: 26.406795501708984\n",
      "Epoch: 695 | recon_loss: 7.20163631439209 | latent_loss: 41.379276275634766 | total_loss: 24.290456771850586\n",
      "Epoch: 696 | recon_loss: 7.326888084411621 | latent_loss: 38.606388092041016 | total_loss: 22.966638565063477\n",
      "Epoch: 697 | recon_loss: 7.321547031402588 | latent_loss: 37.791664123535156 | total_loss: 22.55660629272461\n",
      "Epoch: 698 | recon_loss: 7.3985748291015625 | latent_loss: 36.64952087402344 | total_loss: 22.0240478515625\n",
      "Epoch: 699 | recon_loss: 7.442163944244385 | latent_loss: 38.953678131103516 | total_loss: 23.197921752929688\n",
      "Epoch: 700 | recon_loss: 7.411018371582031 | latent_loss: 34.80949401855469 | total_loss: 21.11025619506836\n",
      "Epoch: 701 | recon_loss: 7.376408576965332 | latent_loss: 34.10380172729492 | total_loss: 20.74010467529297\n",
      "Epoch: 702 | recon_loss: 7.333288192749023 | latent_loss: 33.83238220214844 | total_loss: 20.582836151123047\n",
      "Epoch: 703 | recon_loss: 7.312194347381592 | latent_loss: 33.61520767211914 | total_loss: 20.463701248168945\n",
      "Epoch: 704 | recon_loss: 7.291606426239014 | latent_loss: 33.70864486694336 | total_loss: 20.500125885009766\n",
      "Epoch: 705 | recon_loss: 7.2429304122924805 | latent_loss: 33.25747299194336 | total_loss: 20.250202178955078\n",
      "Epoch: 706 | recon_loss: 7.2436933517456055 | latent_loss: 33.40108108520508 | total_loss: 20.3223876953125\n",
      "Epoch: 707 | recon_loss: 7.132955551147461 | latent_loss: 33.45158386230469 | total_loss: 20.29227066040039\n",
      "Epoch: 708 | recon_loss: 7.068460941314697 | latent_loss: 32.760379791259766 | total_loss: 19.91442108154297\n",
      "Epoch: 709 | recon_loss: 7.076655387878418 | latent_loss: 32.74696350097656 | total_loss: 19.91180992126465\n",
      "Epoch: 710 | recon_loss: 7.091826915740967 | latent_loss: 32.712501525878906 | total_loss: 19.902164459228516\n",
      "Epoch: 711 | recon_loss: 7.065120697021484 | latent_loss: 32.47604751586914 | total_loss: 19.770584106445312\n",
      "Epoch: 712 | recon_loss: 7.060639381408691 | latent_loss: 32.344356536865234 | total_loss: 19.702497482299805\n",
      "Epoch: 713 | recon_loss: 7.052966594696045 | latent_loss: 32.08012008666992 | total_loss: 19.566543579101562\n",
      "Epoch: 714 | recon_loss: 7.059576988220215 | latent_loss: 32.194210052490234 | total_loss: 19.626893997192383\n",
      "Epoch: 715 | recon_loss: 7.064640998840332 | latent_loss: 32.11886978149414 | total_loss: 19.591754913330078\n",
      "Epoch: 716 | recon_loss: 7.120885848999023 | latent_loss: 31.99517822265625 | total_loss: 19.558032989501953\n",
      "Epoch: 717 | recon_loss: 7.146999359130859 | latent_loss: 31.94142723083496 | total_loss: 19.544212341308594\n",
      "Epoch: 718 | recon_loss: 7.064208030700684 | latent_loss: 31.785593032836914 | total_loss: 19.42490005493164\n",
      "Epoch: 719 | recon_loss: 7.147766590118408 | latent_loss: 32.54579162597656 | total_loss: 19.846778869628906\n",
      "Epoch: 720 | recon_loss: 7.154300689697266 | latent_loss: 31.71696662902832 | total_loss: 19.43563461303711\n",
      "Epoch: 721 | recon_loss: 7.070797443389893 | latent_loss: 31.963722229003906 | total_loss: 19.51725959777832\n",
      "Epoch: 722 | recon_loss: 6.999024868011475 | latent_loss: 32.24629211425781 | total_loss: 19.622657775878906\n",
      "Epoch: 723 | recon_loss: 6.985848426818848 | latent_loss: 31.436288833618164 | total_loss: 19.211069107055664\n",
      "Epoch: 724 | recon_loss: 6.995449066162109 | latent_loss: 32.00312805175781 | total_loss: 19.49928855895996\n",
      "Epoch: 725 | recon_loss: 6.926597595214844 | latent_loss: 31.80302619934082 | total_loss: 19.364810943603516\n",
      "Epoch: 726 | recon_loss: 6.913185119628906 | latent_loss: 31.59166145324707 | total_loss: 19.252422332763672\n",
      "Epoch: 727 | recon_loss: 6.8985209465026855 | latent_loss: 31.53172492980957 | total_loss: 19.21512222290039\n",
      "Epoch: 728 | recon_loss: 6.936859130859375 | latent_loss: 31.292741775512695 | total_loss: 19.11479949951172\n",
      "Epoch: 729 | recon_loss: 6.881507873535156 | latent_loss: 31.433719635009766 | total_loss: 19.15761375427246\n",
      "Epoch: 730 | recon_loss: 6.748405456542969 | latent_loss: 31.533329010009766 | total_loss: 19.140867233276367\n",
      "Epoch: 731 | recon_loss: 6.636160850524902 | latent_loss: 31.527870178222656 | total_loss: 19.082015991210938\n",
      "Epoch: 732 | recon_loss: 6.628045082092285 | latent_loss: 31.79306411743164 | total_loss: 19.210554122924805\n",
      "Epoch: 733 | recon_loss: 6.629688262939453 | latent_loss: 31.49098014831543 | total_loss: 19.060333251953125\n",
      "Epoch: 734 | recon_loss: 6.654698371887207 | latent_loss: 31.413856506347656 | total_loss: 19.034276962280273\n",
      "Epoch: 735 | recon_loss: 6.681550979614258 | latent_loss: 31.278289794921875 | total_loss: 18.97991943359375\n",
      "Epoch: 736 | recon_loss: 6.691240310668945 | latent_loss: 31.09299659729004 | total_loss: 18.892118453979492\n",
      "Epoch: 737 | recon_loss: 6.678903102874756 | latent_loss: 31.37404441833496 | total_loss: 19.026473999023438\n",
      "Epoch: 738 | recon_loss: 6.678351402282715 | latent_loss: 30.84129524230957 | total_loss: 18.759822845458984\n",
      "Epoch: 739 | recon_loss: 6.6708784103393555 | latent_loss: 30.68671417236328 | total_loss: 18.678796768188477\n",
      "Epoch: 740 | recon_loss: 6.715023994445801 | latent_loss: 30.8101806640625 | total_loss: 18.762601852416992\n",
      "Epoch: 741 | recon_loss: 6.68264102935791 | latent_loss: 30.686214447021484 | total_loss: 18.68442726135254\n",
      "Epoch: 742 | recon_loss: 6.658836364746094 | latent_loss: 30.996625900268555 | total_loss: 18.82773208618164\n",
      "Epoch: 743 | recon_loss: 6.749665260314941 | latent_loss: 30.70096778869629 | total_loss: 18.725317001342773\n",
      "Epoch: 744 | recon_loss: 6.906118392944336 | latent_loss: 30.686323165893555 | total_loss: 18.796220779418945\n",
      "Epoch: 745 | recon_loss: 7.00338888168335 | latent_loss: 30.968719482421875 | total_loss: 18.986053466796875\n",
      "Epoch: 746 | recon_loss: 7.0462751388549805 | latent_loss: 30.750247955322266 | total_loss: 18.89826202392578\n",
      "Epoch: 747 | recon_loss: 7.046640396118164 | latent_loss: 30.78266143798828 | total_loss: 18.914649963378906\n",
      "Epoch: 748 | recon_loss: 7.01120138168335 | latent_loss: 30.82484245300293 | total_loss: 18.91802215576172\n",
      "Epoch: 749 | recon_loss: 6.993546485900879 | latent_loss: 31.045040130615234 | total_loss: 19.0192928314209\n",
      "Epoch: 750 | recon_loss: 6.991148948669434 | latent_loss: 30.90289306640625 | total_loss: 18.947021484375\n",
      "Epoch: 751 | recon_loss: 7.378287315368652 | latent_loss: 32.421260833740234 | total_loss: 19.8997745513916\n",
      "Epoch: 752 | recon_loss: 7.089391708374023 | latent_loss: 35.173683166503906 | total_loss: 21.13153839111328\n",
      "Epoch: 753 | recon_loss: 7.035030364990234 | latent_loss: 35.37800979614258 | total_loss: 21.206520080566406\n",
      "Epoch: 754 | recon_loss: 6.94950008392334 | latent_loss: 33.81916046142578 | total_loss: 20.38433074951172\n",
      "Epoch: 755 | recon_loss: 6.88690185546875 | latent_loss: 33.07794189453125 | total_loss: 19.982421875\n",
      "Epoch: 756 | recon_loss: 6.833049297332764 | latent_loss: 32.12785339355469 | total_loss: 19.480451583862305\n",
      "Epoch: 757 | recon_loss: 6.843580722808838 | latent_loss: 32.81468200683594 | total_loss: 19.829132080078125\n",
      "Epoch: 758 | recon_loss: 6.994728088378906 | latent_loss: 32.85115051269531 | total_loss: 19.92293930053711\n",
      "Epoch: 759 | recon_loss: 6.7610673904418945 | latent_loss: 33.776424407958984 | total_loss: 20.26874542236328\n",
      "Epoch: 760 | recon_loss: 6.719733238220215 | latent_loss: 33.48145294189453 | total_loss: 20.10059356689453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 761 | recon_loss: 6.787367343902588 | latent_loss: 32.39741134643555 | total_loss: 19.592390060424805\n",
      "Epoch: 762 | recon_loss: 6.871281623840332 | latent_loss: 31.59150505065918 | total_loss: 19.231393814086914\n",
      "Epoch: 763 | recon_loss: 6.914764881134033 | latent_loss: 31.49207305908203 | total_loss: 19.203418731689453\n",
      "Epoch: 764 | recon_loss: 6.894415855407715 | latent_loss: 31.43354034423828 | total_loss: 19.163978576660156\n",
      "Epoch: 765 | recon_loss: 6.936920166015625 | latent_loss: 30.67411994934082 | total_loss: 18.805519104003906\n",
      "Epoch: 766 | recon_loss: 6.951014041900635 | latent_loss: 30.88152313232422 | total_loss: 18.916269302368164\n",
      "Epoch: 767 | recon_loss: 6.957303524017334 | latent_loss: 30.917503356933594 | total_loss: 18.937402725219727\n",
      "Epoch: 768 | recon_loss: 6.977301597595215 | latent_loss: 30.58685302734375 | total_loss: 18.78207778930664\n",
      "Epoch: 769 | recon_loss: 6.93321418762207 | latent_loss: 30.76237678527832 | total_loss: 18.847795486450195\n",
      "Epoch: 770 | recon_loss: 6.901431083679199 | latent_loss: 30.916282653808594 | total_loss: 18.908857345581055\n",
      "Epoch: 771 | recon_loss: 6.8780717849731445 | latent_loss: 30.72772979736328 | total_loss: 18.802900314331055\n",
      "Epoch: 772 | recon_loss: 6.825345993041992 | latent_loss: 30.673561096191406 | total_loss: 18.749454498291016\n",
      "Epoch: 773 | recon_loss: 6.691277503967285 | latent_loss: 31.104326248168945 | total_loss: 18.897802352905273\n",
      "Epoch: 774 | recon_loss: 6.666651725769043 | latent_loss: 31.080251693725586 | total_loss: 18.873451232910156\n",
      "Epoch: 775 | recon_loss: 6.656241416931152 | latent_loss: 31.15721893310547 | total_loss: 18.90673065185547\n",
      "Epoch: 776 | recon_loss: 6.646669387817383 | latent_loss: 30.785762786865234 | total_loss: 18.716217041015625\n",
      "Epoch: 777 | recon_loss: 6.656075477600098 | latent_loss: 30.82749366760254 | total_loss: 18.741785049438477\n",
      "Epoch: 778 | recon_loss: 6.665885925292969 | latent_loss: 30.682233810424805 | total_loss: 18.674060821533203\n",
      "Epoch: 779 | recon_loss: 6.670701503753662 | latent_loss: 30.31588363647461 | total_loss: 18.4932918548584\n",
      "Epoch: 780 | recon_loss: 6.677242755889893 | latent_loss: 30.601261138916016 | total_loss: 18.639251708984375\n",
      "Epoch: 781 | recon_loss: 6.6798295974731445 | latent_loss: 30.74352264404297 | total_loss: 18.7116756439209\n",
      "Epoch: 782 | recon_loss: 6.684849739074707 | latent_loss: 30.37476921081543 | total_loss: 18.529809951782227\n",
      "Epoch: 783 | recon_loss: 6.658433437347412 | latent_loss: 30.57425308227539 | total_loss: 18.616342544555664\n",
      "Epoch: 784 | recon_loss: 6.636824131011963 | latent_loss: 30.30012321472168 | total_loss: 18.468473434448242\n",
      "Epoch: 785 | recon_loss: 6.623461723327637 | latent_loss: 30.289398193359375 | total_loss: 18.456430435180664\n",
      "Epoch: 786 | recon_loss: 6.615988731384277 | latent_loss: 30.801422119140625 | total_loss: 18.70870590209961\n",
      "Epoch: 787 | recon_loss: 6.579602241516113 | latent_loss: 30.243452072143555 | total_loss: 18.411527633666992\n",
      "Epoch: 788 | recon_loss: 6.687770843505859 | latent_loss: 30.80172348022461 | total_loss: 18.744747161865234\n",
      "Epoch: 789 | recon_loss: 6.879148006439209 | latent_loss: 30.47724151611328 | total_loss: 18.678194046020508\n",
      "Epoch: 790 | recon_loss: 6.84673547744751 | latent_loss: 30.44744873046875 | total_loss: 18.647092819213867\n",
      "Epoch: 791 | recon_loss: 6.825874328613281 | latent_loss: 30.234378814697266 | total_loss: 18.530126571655273\n",
      "Epoch: 792 | recon_loss: 6.781487464904785 | latent_loss: 30.174888610839844 | total_loss: 18.478187561035156\n",
      "Epoch: 793 | recon_loss: 6.715607643127441 | latent_loss: 30.13286018371582 | total_loss: 18.42423439025879\n",
      "Epoch: 794 | recon_loss: 6.665562629699707 | latent_loss: 30.02265739440918 | total_loss: 18.3441104888916\n",
      "Epoch: 795 | recon_loss: 6.636831760406494 | latent_loss: 30.19993782043457 | total_loss: 18.418384552001953\n",
      "Epoch: 796 | recon_loss: 6.601199150085449 | latent_loss: 30.271385192871094 | total_loss: 18.43629264831543\n",
      "Epoch: 797 | recon_loss: 6.0841145515441895 | latent_loss: 31.1993408203125 | total_loss: 18.641727447509766\n",
      "Epoch: 798 | recon_loss: 6.001770973205566 | latent_loss: 31.256317138671875 | total_loss: 18.629043579101562\n",
      "Epoch: 799 | recon_loss: 6.007841110229492 | latent_loss: 31.45340919494629 | total_loss: 18.73062515258789\n",
      "Epoch: 800 | recon_loss: 6.062437057495117 | latent_loss: 31.086509704589844 | total_loss: 18.574474334716797\n",
      "Epoch: 801 | recon_loss: 6.125446319580078 | latent_loss: 30.466670989990234 | total_loss: 18.296058654785156\n",
      "Epoch: 802 | recon_loss: 6.160434722900391 | latent_loss: 30.96288299560547 | total_loss: 18.56165885925293\n",
      "Epoch: 803 | recon_loss: 6.2036519050598145 | latent_loss: 30.27541160583496 | total_loss: 18.239532470703125\n",
      "Epoch: 804 | recon_loss: 6.219551086425781 | latent_loss: 30.232534408569336 | total_loss: 18.226043701171875\n",
      "Epoch: 805 | recon_loss: 6.23176383972168 | latent_loss: 29.94824981689453 | total_loss: 18.090007781982422\n",
      "Epoch: 806 | recon_loss: 6.2575907707214355 | latent_loss: 29.87803840637207 | total_loss: 18.067813873291016\n",
      "Epoch: 807 | recon_loss: 6.255206108093262 | latent_loss: 29.73468780517578 | total_loss: 17.99494743347168\n",
      "Epoch: 808 | recon_loss: 6.242187976837158 | latent_loss: 30.13189697265625 | total_loss: 18.187042236328125\n",
      "Epoch: 809 | recon_loss: 6.256250858306885 | latent_loss: 30.41952133178711 | total_loss: 18.337886810302734\n",
      "Epoch: 810 | recon_loss: 6.273586273193359 | latent_loss: 29.96597671508789 | total_loss: 18.119781494140625\n",
      "Epoch: 811 | recon_loss: 6.291647911071777 | latent_loss: 29.939212799072266 | total_loss: 18.11543083190918\n",
      "Epoch: 812 | recon_loss: 6.2972211837768555 | latent_loss: 30.07013702392578 | total_loss: 18.183679580688477\n",
      "Epoch: 813 | recon_loss: 6.307322978973389 | latent_loss: 30.023637771606445 | total_loss: 18.16547966003418\n",
      "Epoch: 814 | recon_loss: 6.313897609710693 | latent_loss: 30.061635971069336 | total_loss: 18.187767028808594\n",
      "Epoch: 815 | recon_loss: 6.325048446655273 | latent_loss: 29.847373962402344 | total_loss: 18.086212158203125\n",
      "Epoch: 816 | recon_loss: 6.307916164398193 | latent_loss: 29.82899284362793 | total_loss: 18.06845474243164\n",
      "Epoch: 817 | recon_loss: 6.321202278137207 | latent_loss: 30.005859375 | total_loss: 18.163530349731445\n",
      "Epoch: 818 | recon_loss: 6.509511947631836 | latent_loss: 29.80991554260254 | total_loss: 18.159713745117188\n",
      "Epoch: 819 | recon_loss: 6.593382835388184 | latent_loss: 29.92259979248047 | total_loss: 18.257991790771484\n",
      "Epoch: 820 | recon_loss: 6.581535339355469 | latent_loss: 30.014299392700195 | total_loss: 18.297916412353516\n",
      "Epoch: 821 | recon_loss: 6.530364036560059 | latent_loss: 29.82447052001953 | total_loss: 18.177417755126953\n",
      "Epoch: 822 | recon_loss: 6.503650665283203 | latent_loss: 29.705955505371094 | total_loss: 18.10480308532715\n",
      "Epoch: 823 | recon_loss: 6.320032119750977 | latent_loss: 30.371341705322266 | total_loss: 18.345687866210938\n",
      "Epoch: 824 | recon_loss: 6.2228851318359375 | latent_loss: 29.701568603515625 | total_loss: 17.96222686767578\n",
      "Epoch: 825 | recon_loss: 6.18467903137207 | latent_loss: 30.637556076049805 | total_loss: 18.411117553710938\n",
      "Epoch: 826 | recon_loss: 6.1995849609375 | latent_loss: 29.82653045654297 | total_loss: 18.013057708740234\n",
      "Epoch: 827 | recon_loss: 6.217709064483643 | latent_loss: 29.78371810913086 | total_loss: 18.000713348388672\n",
      "Epoch: 828 | recon_loss: 6.240427017211914 | latent_loss: 29.839094161987305 | total_loss: 18.03976058959961\n",
      "Epoch: 829 | recon_loss: 6.283153533935547 | latent_loss: 29.82772445678711 | total_loss: 18.055438995361328\n",
      "Epoch: 830 | recon_loss: 6.294919967651367 | latent_loss: 29.56281280517578 | total_loss: 17.92886734008789\n",
      "Epoch: 831 | recon_loss: 6.304516792297363 | latent_loss: 29.611135482788086 | total_loss: 17.957826614379883\n",
      "Epoch: 832 | recon_loss: 6.306829929351807 | latent_loss: 29.36338233947754 | total_loss: 17.835105895996094\n",
      "Epoch: 833 | recon_loss: 6.300745010375977 | latent_loss: 29.55322265625 | total_loss: 17.926982879638672\n",
      "Epoch: 834 | recon_loss: 6.3006591796875 | latent_loss: 29.58430290222168 | total_loss: 17.942481994628906\n",
      "Epoch: 835 | recon_loss: 6.296557903289795 | latent_loss: 29.42398452758789 | total_loss: 17.860271453857422\n",
      "Epoch: 836 | recon_loss: 6.296858787536621 | latent_loss: 29.521827697753906 | total_loss: 17.909343719482422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 837 | recon_loss: 6.29475212097168 | latent_loss: 29.54283332824707 | total_loss: 17.918792724609375\n",
      "Epoch: 838 | recon_loss: 6.294685363769531 | latent_loss: 29.568477630615234 | total_loss: 17.931581497192383\n",
      "Epoch: 839 | recon_loss: 6.294872760772705 | latent_loss: 29.56403923034668 | total_loss: 17.92945671081543\n",
      "Epoch: 840 | recon_loss: 6.290407180786133 | latent_loss: 29.637760162353516 | total_loss: 17.96408462524414\n",
      "Epoch: 841 | recon_loss: 6.289119720458984 | latent_loss: 29.449424743652344 | total_loss: 17.869272232055664\n",
      "Epoch: 842 | recon_loss: 6.291043281555176 | latent_loss: 29.412824630737305 | total_loss: 17.8519344329834\n",
      "Epoch: 843 | recon_loss: 6.293761253356934 | latent_loss: 29.406389236450195 | total_loss: 17.850074768066406\n",
      "Epoch: 844 | recon_loss: 6.290153503417969 | latent_loss: 29.27178192138672 | total_loss: 17.780967712402344\n",
      "Epoch: 845 | recon_loss: 6.292619228363037 | latent_loss: 29.595455169677734 | total_loss: 17.94403648376465\n",
      "Epoch: 846 | recon_loss: 6.294354438781738 | latent_loss: 29.413705825805664 | total_loss: 17.85403060913086\n",
      "Epoch: 847 | recon_loss: 6.299745559692383 | latent_loss: 29.42288589477539 | total_loss: 17.861316680908203\n",
      "Epoch: 848 | recon_loss: 6.296531677246094 | latent_loss: 29.394094467163086 | total_loss: 17.845314025878906\n",
      "Epoch: 849 | recon_loss: 6.301295280456543 | latent_loss: 28.992055892944336 | total_loss: 17.64667510986328\n",
      "Epoch: 850 | recon_loss: 6.306691646575928 | latent_loss: 29.363447189331055 | total_loss: 17.83506965637207\n",
      "Epoch: 851 | recon_loss: 6.306057453155518 | latent_loss: 29.28199005126953 | total_loss: 17.794023513793945\n",
      "Epoch: 852 | recon_loss: 6.306600570678711 | latent_loss: 29.23657989501953 | total_loss: 17.771591186523438\n",
      "Epoch: 853 | recon_loss: 6.302085876464844 | latent_loss: 29.318342208862305 | total_loss: 17.81021499633789\n",
      "Epoch: 854 | recon_loss: 6.298657417297363 | latent_loss: 29.382972717285156 | total_loss: 17.8408145904541\n",
      "Epoch: 855 | recon_loss: 6.299699783325195 | latent_loss: 29.28772735595703 | total_loss: 17.793712615966797\n",
      "Epoch: 856 | recon_loss: 6.316854953765869 | latent_loss: 29.47496223449707 | total_loss: 17.89590835571289\n",
      "Epoch: 857 | recon_loss: 6.315494537353516 | latent_loss: 29.24496841430664 | total_loss: 17.780231475830078\n",
      "Epoch: 858 | recon_loss: 6.30761194229126 | latent_loss: 29.085723876953125 | total_loss: 17.69666862487793\n",
      "Epoch: 859 | recon_loss: 6.306275367736816 | latent_loss: 29.30286407470703 | total_loss: 17.804569244384766\n",
      "Epoch: 860 | recon_loss: 6.318050384521484 | latent_loss: 29.19561767578125 | total_loss: 17.756834030151367\n",
      "Epoch: 861 | recon_loss: 6.315281867980957 | latent_loss: 28.934438705444336 | total_loss: 17.624860763549805\n",
      "Epoch: 862 | recon_loss: 6.304353713989258 | latent_loss: 29.18276596069336 | total_loss: 17.743560791015625\n",
      "Epoch: 863 | recon_loss: 6.297478199005127 | latent_loss: 29.127418518066406 | total_loss: 17.712448120117188\n",
      "Epoch: 864 | recon_loss: 6.312993049621582 | latent_loss: 29.14133644104004 | total_loss: 17.72716522216797\n",
      "Epoch: 865 | recon_loss: 6.318486213684082 | latent_loss: 29.22579002380371 | total_loss: 17.772138595581055\n",
      "Epoch: 866 | recon_loss: 6.319356918334961 | latent_loss: 29.26984977722168 | total_loss: 17.79460334777832\n",
      "Epoch: 867 | recon_loss: 6.3192362785339355 | latent_loss: 29.025421142578125 | total_loss: 17.67232894897461\n",
      "Epoch: 868 | recon_loss: 6.314113616943359 | latent_loss: 28.98023223876953 | total_loss: 17.647172927856445\n",
      "Epoch: 869 | recon_loss: 6.309975624084473 | latent_loss: 29.04786491394043 | total_loss: 17.67892074584961\n",
      "Epoch: 870 | recon_loss: 6.305205345153809 | latent_loss: 29.082406997680664 | total_loss: 17.693805694580078\n",
      "Epoch: 871 | recon_loss: 6.29946231842041 | latent_loss: 29.068119049072266 | total_loss: 17.68379020690918\n",
      "Epoch: 872 | recon_loss: 6.305837631225586 | latent_loss: 28.95703125 | total_loss: 17.63143539428711\n",
      "Epoch: 873 | recon_loss: 6.306057929992676 | latent_loss: 29.242204666137695 | total_loss: 17.774131774902344\n",
      "Epoch: 874 | recon_loss: 6.302847862243652 | latent_loss: 29.15375518798828 | total_loss: 17.728302001953125\n",
      "Epoch: 875 | recon_loss: 6.297667503356934 | latent_loss: 29.03236961364746 | total_loss: 17.66501808166504\n",
      "Epoch: 876 | recon_loss: 6.294704914093018 | latent_loss: 29.03560447692871 | total_loss: 17.6651554107666\n",
      "Epoch: 877 | recon_loss: 6.292477130889893 | latent_loss: 28.99857521057129 | total_loss: 17.645526885986328\n",
      "Epoch: 878 | recon_loss: 6.289478302001953 | latent_loss: 29.0689697265625 | total_loss: 17.679224014282227\n",
      "Epoch: 879 | recon_loss: 6.290493011474609 | latent_loss: 28.89828872680664 | total_loss: 17.594390869140625\n",
      "Epoch: 880 | recon_loss: 6.290622711181641 | latent_loss: 29.12004852294922 | total_loss: 17.70533561706543\n",
      "Epoch: 881 | recon_loss: 6.290284156799316 | latent_loss: 28.927001953125 | total_loss: 17.608642578125\n",
      "Epoch: 882 | recon_loss: 6.289433002471924 | latent_loss: 28.85280990600586 | total_loss: 17.571121215820312\n",
      "Epoch: 883 | recon_loss: 6.289359092712402 | latent_loss: 29.02420997619629 | total_loss: 17.656784057617188\n",
      "Epoch: 884 | recon_loss: 6.291003704071045 | latent_loss: 28.73197364807129 | total_loss: 17.51148796081543\n",
      "Epoch: 885 | recon_loss: 6.288101673126221 | latent_loss: 29.07960319519043 | total_loss: 17.683853149414062\n",
      "Epoch: 886 | recon_loss: 6.288098335266113 | latent_loss: 28.93564796447754 | total_loss: 17.611873626708984\n",
      "Epoch: 887 | recon_loss: 6.28730583190918 | latent_loss: 28.983388900756836 | total_loss: 17.635347366333008\n",
      "Epoch: 888 | recon_loss: 6.289410591125488 | latent_loss: 28.87930679321289 | total_loss: 17.58435821533203\n",
      "Epoch: 889 | recon_loss: 6.289857387542725 | latent_loss: 28.97106170654297 | total_loss: 17.63045883178711\n",
      "Epoch: 890 | recon_loss: 6.291388988494873 | latent_loss: 28.75288200378418 | total_loss: 17.52213478088379\n",
      "Epoch: 891 | recon_loss: 6.286182403564453 | latent_loss: 29.02994155883789 | total_loss: 17.658061981201172\n",
      "Epoch: 892 | recon_loss: 6.2851338386535645 | latent_loss: 28.916378021240234 | total_loss: 17.60075569152832\n",
      "Epoch: 893 | recon_loss: 6.286972999572754 | latent_loss: 28.95327377319336 | total_loss: 17.6201229095459\n",
      "Epoch: 894 | recon_loss: 6.287487983703613 | latent_loss: 29.00752830505371 | total_loss: 17.64750862121582\n",
      "Epoch: 895 | recon_loss: 6.282114028930664 | latent_loss: 28.63846778869629 | total_loss: 17.460290908813477\n",
      "Epoch: 896 | recon_loss: 6.278594970703125 | latent_loss: 29.06104850769043 | total_loss: 17.669822692871094\n",
      "Epoch: 897 | recon_loss: 6.2774739265441895 | latent_loss: 28.86625862121582 | total_loss: 17.571866989135742\n",
      "Epoch: 898 | recon_loss: 6.277932167053223 | latent_loss: 28.901573181152344 | total_loss: 17.589752197265625\n",
      "Epoch: 899 | recon_loss: 6.280825614929199 | latent_loss: 28.961809158325195 | total_loss: 17.62131690979004\n",
      "Epoch: 900 | recon_loss: 6.280927658081055 | latent_loss: 29.009748458862305 | total_loss: 17.64533805847168\n",
      "Epoch: 901 | recon_loss: 6.27752685546875 | latent_loss: 28.84866714477539 | total_loss: 17.56309700012207\n",
      "Epoch: 902 | recon_loss: 6.275517463684082 | latent_loss: 28.808956146240234 | total_loss: 17.542236328125\n",
      "Epoch: 903 | recon_loss: 6.273889541625977 | latent_loss: 28.935482025146484 | total_loss: 17.604686737060547\n",
      "Epoch: 904 | recon_loss: 6.275238037109375 | latent_loss: 28.806814193725586 | total_loss: 17.541027069091797\n",
      "Epoch: 905 | recon_loss: 6.274328231811523 | latent_loss: 28.66574478149414 | total_loss: 17.470035552978516\n",
      "Epoch: 906 | recon_loss: 6.27431583404541 | latent_loss: 28.750797271728516 | total_loss: 17.512556076049805\n",
      "Epoch: 907 | recon_loss: 6.276810169219971 | latent_loss: 28.692331314086914 | total_loss: 17.48457145690918\n",
      "Epoch: 908 | recon_loss: 6.274381637573242 | latent_loss: 28.79599380493164 | total_loss: 17.535186767578125\n",
      "Epoch: 909 | recon_loss: 6.27497673034668 | latent_loss: 28.60770034790039 | total_loss: 17.44133758544922\n",
      "Epoch: 910 | recon_loss: 6.275538921356201 | latent_loss: 28.832603454589844 | total_loss: 17.5540714263916\n",
      "Epoch: 911 | recon_loss: 6.274345397949219 | latent_loss: 28.45243263244629 | total_loss: 17.363388061523438\n",
      "Epoch: 912 | recon_loss: 6.270875930786133 | latent_loss: 28.726470947265625 | total_loss: 17.498672485351562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 913 | recon_loss: 6.268655776977539 | latent_loss: 28.718610763549805 | total_loss: 17.493633270263672\n",
      "Epoch: 914 | recon_loss: 6.268030166625977 | latent_loss: 28.713138580322266 | total_loss: 17.490585327148438\n",
      "Epoch: 915 | recon_loss: 6.271088600158691 | latent_loss: 28.72159767150879 | total_loss: 17.4963436126709\n",
      "Epoch: 916 | recon_loss: 6.271322250366211 | latent_loss: 28.709150314331055 | total_loss: 17.490236282348633\n",
      "Epoch: 917 | recon_loss: 6.268927574157715 | latent_loss: 28.66217803955078 | total_loss: 17.465553283691406\n",
      "Epoch: 918 | recon_loss: 6.266372203826904 | latent_loss: 28.742008209228516 | total_loss: 17.50419044494629\n",
      "Epoch: 919 | recon_loss: 6.265869140625 | latent_loss: 28.67138671875 | total_loss: 17.4686279296875\n",
      "Epoch: 920 | recon_loss: 6.264326095581055 | latent_loss: 28.93964385986328 | total_loss: 17.601985931396484\n",
      "Epoch: 921 | recon_loss: 6.2623677253723145 | latent_loss: 28.47438621520996 | total_loss: 17.368377685546875\n",
      "Epoch: 922 | recon_loss: 6.261899948120117 | latent_loss: 28.69815444946289 | total_loss: 17.480026245117188\n",
      "Epoch: 923 | recon_loss: 6.258434295654297 | latent_loss: 28.7056884765625 | total_loss: 17.4820613861084\n",
      "Epoch: 924 | recon_loss: 6.253332614898682 | latent_loss: 28.572166442871094 | total_loss: 17.412750244140625\n",
      "Epoch: 925 | recon_loss: 6.254487037658691 | latent_loss: 28.55112648010254 | total_loss: 17.402807235717773\n",
      "Epoch: 926 | recon_loss: 6.254575729370117 | latent_loss: 28.6060791015625 | total_loss: 17.430328369140625\n",
      "Epoch: 927 | recon_loss: 6.25211238861084 | latent_loss: 28.705976486206055 | total_loss: 17.47904396057129\n",
      "Epoch: 928 | recon_loss: 6.253434658050537 | latent_loss: 28.578256607055664 | total_loss: 17.41584587097168\n",
      "Epoch: 929 | recon_loss: 6.253644943237305 | latent_loss: 28.590267181396484 | total_loss: 17.421955108642578\n",
      "Epoch: 930 | recon_loss: 6.249272346496582 | latent_loss: 28.70517349243164 | total_loss: 17.477222442626953\n",
      "Epoch: 931 | recon_loss: 6.244521141052246 | latent_loss: 28.482818603515625 | total_loss: 17.363670349121094\n",
      "Epoch: 932 | recon_loss: 6.240909576416016 | latent_loss: 28.72212791442871 | total_loss: 17.481517791748047\n",
      "Epoch: 933 | recon_loss: 6.241547584533691 | latent_loss: 28.466400146484375 | total_loss: 17.353973388671875\n",
      "Epoch: 934 | recon_loss: 6.244576930999756 | latent_loss: 28.49149513244629 | total_loss: 17.3680362701416\n",
      "Epoch: 935 | recon_loss: 6.246293067932129 | latent_loss: 28.445112228393555 | total_loss: 17.345703125\n",
      "Epoch: 936 | recon_loss: 6.244434833526611 | latent_loss: 28.524864196777344 | total_loss: 17.3846492767334\n",
      "Epoch: 937 | recon_loss: 6.244252681732178 | latent_loss: 28.50558853149414 | total_loss: 17.374919891357422\n",
      "Epoch: 938 | recon_loss: 6.243854522705078 | latent_loss: 28.59494972229004 | total_loss: 17.419403076171875\n",
      "Epoch: 939 | recon_loss: 6.247225761413574 | latent_loss: 28.519569396972656 | total_loss: 17.383398056030273\n",
      "Epoch: 940 | recon_loss: 6.246649742126465 | latent_loss: 28.583513259887695 | total_loss: 17.415081024169922\n",
      "Epoch: 941 | recon_loss: 6.241147041320801 | latent_loss: 28.428691864013672 | total_loss: 17.334918975830078\n",
      "Epoch: 942 | recon_loss: 6.238962173461914 | latent_loss: 28.626590728759766 | total_loss: 17.432777404785156\n",
      "Epoch: 943 | recon_loss: 6.236501693725586 | latent_loss: 28.489728927612305 | total_loss: 17.363115310668945\n",
      "Epoch: 944 | recon_loss: 6.236565589904785 | latent_loss: 28.37116813659668 | total_loss: 17.30386734008789\n",
      "Epoch: 945 | recon_loss: 6.233377456665039 | latent_loss: 28.69843864440918 | total_loss: 17.46590805053711\n",
      "Epoch: 946 | recon_loss: 6.230186462402344 | latent_loss: 28.365501403808594 | total_loss: 17.29784393310547\n",
      "Epoch: 947 | recon_loss: 6.229964256286621 | latent_loss: 28.400482177734375 | total_loss: 17.315223693847656\n",
      "Epoch: 948 | recon_loss: 6.2291741371154785 | latent_loss: 28.41151237487793 | total_loss: 17.320343017578125\n",
      "Epoch: 949 | recon_loss: 6.231659889221191 | latent_loss: 28.38001251220703 | total_loss: 17.305835723876953\n",
      "Epoch: 950 | recon_loss: 6.232199668884277 | latent_loss: 28.36640167236328 | total_loss: 17.299301147460938\n",
      "Epoch: 951 | recon_loss: 6.2273969650268555 | latent_loss: 28.53941535949707 | total_loss: 17.383405685424805\n",
      "Epoch: 952 | recon_loss: 6.224874019622803 | latent_loss: 28.418468475341797 | total_loss: 17.321670532226562\n",
      "Epoch: 953 | recon_loss: 6.221642017364502 | latent_loss: 28.29999542236328 | total_loss: 17.260818481445312\n",
      "Epoch: 954 | recon_loss: 6.221964359283447 | latent_loss: 28.28430938720703 | total_loss: 17.253137588500977\n",
      "Epoch: 955 | recon_loss: 6.221961975097656 | latent_loss: 28.321535110473633 | total_loss: 17.271747589111328\n",
      "Epoch: 956 | recon_loss: 6.222349166870117 | latent_loss: 28.343801498413086 | total_loss: 17.2830753326416\n",
      "Epoch: 957 | recon_loss: 6.223367691040039 | latent_loss: 28.294593811035156 | total_loss: 17.25897979736328\n",
      "Epoch: 958 | recon_loss: 6.222754955291748 | latent_loss: 28.17252540588379 | total_loss: 17.19763946533203\n",
      "Epoch: 959 | recon_loss: 6.222665309906006 | latent_loss: 28.567304611206055 | total_loss: 17.39498519897461\n",
      "Epoch: 960 | recon_loss: 6.221742630004883 | latent_loss: 28.304738998413086 | total_loss: 17.263240814208984\n",
      "Epoch: 961 | recon_loss: 6.222892761230469 | latent_loss: 28.359703063964844 | total_loss: 17.291297912597656\n",
      "Epoch: 962 | recon_loss: 6.220808029174805 | latent_loss: 28.15764617919922 | total_loss: 17.189228057861328\n",
      "Epoch: 963 | recon_loss: 6.230554103851318 | latent_loss: 28.513715744018555 | total_loss: 17.372135162353516\n",
      "Epoch: 964 | recon_loss: 6.233063697814941 | latent_loss: 28.340946197509766 | total_loss: 17.287004470825195\n",
      "Epoch: 965 | recon_loss: 6.226495742797852 | latent_loss: 28.32393455505371 | total_loss: 17.27521514892578\n",
      "Epoch: 966 | recon_loss: 6.229681491851807 | latent_loss: 28.546316146850586 | total_loss: 17.387998580932617\n",
      "Epoch: 967 | recon_loss: 6.228388786315918 | latent_loss: 28.15076446533203 | total_loss: 17.189577102661133\n",
      "Epoch: 968 | recon_loss: 6.223424911499023 | latent_loss: 28.316713333129883 | total_loss: 17.270069122314453\n",
      "Epoch: 969 | recon_loss: 6.221883296966553 | latent_loss: 28.259084701538086 | total_loss: 17.2404842376709\n",
      "Epoch: 970 | recon_loss: 6.2206645011901855 | latent_loss: 28.370914459228516 | total_loss: 17.29578971862793\n",
      "Epoch: 971 | recon_loss: 6.216214179992676 | latent_loss: 28.23004150390625 | total_loss: 17.223127365112305\n",
      "Epoch: 972 | recon_loss: 6.214229583740234 | latent_loss: 28.581865310668945 | total_loss: 17.398048400878906\n",
      "Epoch: 973 | recon_loss: 6.214676856994629 | latent_loss: 28.172582626342773 | total_loss: 17.19363021850586\n",
      "Epoch: 974 | recon_loss: 6.211169719696045 | latent_loss: 28.188867568969727 | total_loss: 17.20001792907715\n",
      "Epoch: 975 | recon_loss: 6.214967727661133 | latent_loss: 28.527069091796875 | total_loss: 17.371017456054688\n",
      "Epoch: 976 | recon_loss: 6.36588716506958 | latent_loss: 28.54191780090332 | total_loss: 17.453903198242188\n",
      "Epoch: 977 | recon_loss: 6.389374732971191 | latent_loss: 28.450531005859375 | total_loss: 17.419952392578125\n",
      "Epoch: 978 | recon_loss: 6.383852005004883 | latent_loss: 28.627498626708984 | total_loss: 17.50567626953125\n",
      "Epoch: 979 | recon_loss: 6.3832597732543945 | latent_loss: 28.21804428100586 | total_loss: 17.30065155029297\n",
      "Epoch: 980 | recon_loss: 6.339555263519287 | latent_loss: 28.32312774658203 | total_loss: 17.331340789794922\n",
      "Epoch: 981 | recon_loss: 6.352416038513184 | latent_loss: 28.59046745300293 | total_loss: 17.4714412689209\n",
      "Epoch: 982 | recon_loss: 6.459166526794434 | latent_loss: 28.071571350097656 | total_loss: 17.265369415283203\n",
      "Epoch: 983 | recon_loss: 6.484192848205566 | latent_loss: 28.47358512878418 | total_loss: 17.47888946533203\n",
      "Epoch: 984 | recon_loss: 6.471982955932617 | latent_loss: 28.289241790771484 | total_loss: 17.380611419677734\n",
      "Epoch: 985 | recon_loss: 6.5185675621032715 | latent_loss: 28.362897872924805 | total_loss: 17.440732955932617\n",
      "Epoch: 986 | recon_loss: 6.529379844665527 | latent_loss: 28.21398162841797 | total_loss: 17.371681213378906\n",
      "Epoch: 987 | recon_loss: 6.497864246368408 | latent_loss: 28.14809799194336 | total_loss: 17.322980880737305\n",
      "Epoch: 988 | recon_loss: 6.4445109367370605 | latent_loss: 28.215965270996094 | total_loss: 17.330238342285156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 989 | recon_loss: 6.380927085876465 | latent_loss: 28.106374740600586 | total_loss: 17.243650436401367\n",
      "Epoch: 990 | recon_loss: 6.371138095855713 | latent_loss: 28.32577133178711 | total_loss: 17.34845542907715\n",
      "Epoch: 991 | recon_loss: 6.331350803375244 | latent_loss: 28.252071380615234 | total_loss: 17.291711807250977\n",
      "Epoch: 992 | recon_loss: 6.277246475219727 | latent_loss: 28.075454711914062 | total_loss: 17.176349639892578\n",
      "Epoch: 993 | recon_loss: 6.17997932434082 | latent_loss: 28.28818130493164 | total_loss: 17.234081268310547\n",
      "Epoch: 994 | recon_loss: 6.14277458190918 | latent_loss: 28.59003448486328 | total_loss: 17.366405487060547\n",
      "Epoch: 995 | recon_loss: 6.233216285705566 | latent_loss: 28.26680564880371 | total_loss: 17.250011444091797\n",
      "Epoch: 996 | recon_loss: 6.259429931640625 | latent_loss: 28.383575439453125 | total_loss: 17.321502685546875\n",
      "Epoch: 997 | recon_loss: 6.2269439697265625 | latent_loss: 28.23432159423828 | total_loss: 17.230632781982422\n",
      "Epoch: 998 | recon_loss: 6.285843849182129 | latent_loss: 28.233827590942383 | total_loss: 17.259836196899414\n",
      "Epoch: 999 | recon_loss: 6.36048698425293 | latent_loss: 28.46337127685547 | total_loss: 17.411930084228516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "N_TRAIN_BATCHES = X_train.shape[0] // BATCH_SIZE\n",
    "N_TEST_BATCHES = X_test.shape[0] // BATCH_SIZE\n",
    "EARLY_STOPPING_ROUNDS = 30\n",
    "\n",
    "losses = pd.DataFrame(columns = ['recon_loss', 'latent_loss'])\n",
    "prev_loss, early_stop_round = np.inf, 0\n",
    "\n",
    "model = VAE(keras.optimizers.Adam(1e-3), hidden_size=4, share_hidden=False)\n",
    "\n",
    "for epoch in tqdm(range(n_epochs), total=n_epochs):\n",
    "    # train\n",
    "    for batch, train_x in zip(range(N_TRAIN_BATCHES), train_dataset):\n",
    "        model.train(train_x)\n",
    "        \n",
    "    # test on holdout\n",
    "    loss = []\n",
    "    for batch, test_x in zip(range(N_TEST_BATCHES), test_dataset):\n",
    "        loss.append(model.compute_loss(train_x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
    "    \n",
    "    # early stopping\n",
    "    round_loss = (losses.recon_loss.values[-1] + losses.latent_loss.values[-1]) / 2\n",
    "    if round_loss < prev_loss:\n",
    "        early_stop_round = 0\n",
    "    else:\n",
    "        early_stop_round += 1\n",
    "        if early_stop_round == EARLY_STOPPING_ROUNDS:\n",
    "            break\n",
    "    prev_loss = round_loss\n",
    "    \n",
    "    print(\n",
    "        \"Epoch: {} | recon_loss: {} | latent_loss: {} | total_loss: {}\".format(\n",
    "           epoch, losses.recon_loss.values[-1], losses.latent_loss.values[-1], round_loss\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a371dd080>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a38400978>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a38427ac8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss throughout the training\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.plot(losses.index, losses.recon_loss, label='recon_loss')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(losses.index, losses.latent_loss, label='latent_loss', color='orange')\n",
    "ax.figure.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "p_z = ds.MultivariateNormalDiag(loc=[0.] * model.hidden_size, scale_diag=[1.] * model.hidden_size)\n",
    "\n",
    "test_tensor = tf.constant(X_test.values, dtype='float32')\n",
    "# mu, sigma = tf.split(model.encoder(test_tensor), 2, 1)\n",
    "encoded = model.encoder(test_tensor)\n",
    "mu, sigma = model.dense_mean(encoded), model.dense_std(encoded)\n",
    "\n",
    "q_z = ds.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
    "test_pred = ds.kl_divergence(p_z, q_z)\n",
    "# test_pred = tf.sigmoid(test_pred)\n",
    "\n",
    "test_pred = test_pred.numpy()\n",
    "test_pred = test_pred / (test_pred.max() - test_pred.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4604745377442654"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
